<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/xxb/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"dmyang-only.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="1、非关系型数据库NoSql：Not-only SQL(泛指非关系型数据库)，作为关系型数据库的补充  redis  MongoDB: Bson格式   作用：应对基于海量用户和海量数据前提下的数据处理问题 特征  可扩容，可伸缩 大数据量下高性能 灵活的数据模型 高可用    2、Redis数据类型Redis提供了String,Hash,List,Set,Zset五种数据类型 StringStr">
<meta property="og:type" content="article">
<meta property="og:title" content="redis">
<meta property="og:url" content="https://dmyang-only.github.io/2020/10/17/Redis/index.html">
<meta property="og:site_name" content="DmYoung">
<meta property="og:description" content="1、非关系型数据库NoSql：Not-only SQL(泛指非关系型数据库)，作为关系型数据库的补充  redis  MongoDB: Bson格式   作用：应对基于海量用户和海量数据前提下的数据处理问题 特征  可扩容，可伸缩 大数据量下高性能 灵活的数据模型 高可用    2、Redis数据类型Redis提供了String,Hash,List,Set,Zset五种数据类型 StringStr">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://csn.damyoung.cn/image-20201027195426479.png">
<meta property="og:image" content="https://csn.damyoung.cn/image-20201027234850342.png">
<meta property="og:image" content="https://csn.damyoung.cn/image-20201030165358794.png">
<meta property="og:image" content="https://csn.damyoung.cn/image-20201031164401584.png">
<meta property="og:image" content="https://csn.damyoung.cn/image-20201101105329319.png">
<meta property="og:image" content="https://csn.damyoung.cn/image-20201101111813388.png">
<meta property="og:image" content="http://qiniu.xiaoming.net.cn/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.jpeg">
<meta property="og:image" content="http://qiniu.xiaoming.net.cn/%E5%8A%A0%E5%85%A5%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E5%90%8E%E7%9A%84%E7%BC%93%E5%AD%98%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://qiniu.xiaoming.net.cn/redis%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.png">
<meta property="og:image" content="https://camo.githubusercontent.com/b1fd3e057266f0ca21f69e2a26f420f9564c5cdb/68747470733a2f2f6d617274696e2e6b6c6570706d616e6e2e636f6d2f323031362f30322f756e736166652d6c6f636b2e706e67">
<meta property="og:image" content="https://camo.githubusercontent.com/4ca3c6919e560b60b130c4f856d2736314713e62/68747470733a2f2f6d617274696e2e6b6c6570706d616e6e2e636f6d2f323031362f30322f66656e63696e672d746f6b656e732e706e67">
<meta property="og:image" content="http://qiniu.xiaoming.net.cn/ziplist%E7%BB%93%E6%9E%84%E5%9B%BE.png">
<meta property="og:image" content="http://qiniu.xiaoming.net.cn/ZSet%E4%B8%ADskiplist%E7%BB%93%E6%9E%84.png">
<meta property="og:image" content="https://camo.githubusercontent.com/11e7cbe718a70a81c42c37a13a257f91ef48dfd7/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d31322d392f39333636363231372e6a7067">
<meta property="og:image" content="http://qiniu.xiaoming.net.cn/%E8%B7%B3%E8%A1%A8%E7%BB%93%E6%9E%842.png">
<meta property="article:published_time" content="2020-10-17T15:33:33.000Z">
<meta property="article:modified_time" content="2020-12-20T15:57:10.908Z">
<meta property="article:author" content="dmYang">
<meta property="article:tag" content="redis">
<meta property="article:tag" content="数据库">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://csn.damyoung.cn/image-20201027195426479.png">

<link rel="canonical" href="https://dmyang-only.github.io/2020/10/17/Redis/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>redis | DmYoung</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">DmYoung</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">记录美好日常</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://dmyang-only.github.io/2020/10/17/Redis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="dmYang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DmYoung">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          redis
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-10-17 23:33:33" itemprop="dateCreated datePublished" datetime="2020-10-17T23:33:33+08:00">2020-10-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-20 23:57:10" itemprop="dateModified" datetime="2020-12-20T23:57:10+08:00">2020-12-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/redis/" itemprop="url" rel="index"><span itemprop="name">redis</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>28k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>25 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="1、非关系型数据库"><a href="#1、非关系型数据库" class="headerlink" title="1、非关系型数据库"></a>1、非关系型数据库</h1><p>NoSql：Not-only SQL(泛指非关系型数据库)，作为关系型数据库的补充</p>
<ul>
<li><p>redis</p>
</li>
<li><p>MongoDB: Bson格式</p>
</li>
</ul>
<p>作用：应对基于海量用户和海量数据前提下的数据处理问题</p>
<p>特征</p>
<ul>
<li>可扩容，可伸缩</li>
<li>大数据量下高性能</li>
<li>灵活的数据模型</li>
<li>高可用</li>
</ul>
<img src="https://csn.damyoung.cn/image-20201027195426479.png" alt="image-20201027195426479" style="zoom:80%;" />

<h1 id="2、Redis数据类型"><a href="#2、Redis数据类型" class="headerlink" title="2、Redis数据类型"></a>2、Redis数据类型</h1><p>Redis提供了<code>String</code>,<code>Hash</code>,<code>List</code>,<code>Set</code>,<code>Zset</code>五种数据类型</p>
<h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><p><code>String</code>数据结构是最简单的<code>key-value</code>类型，<code>value</code>不仅可以是<code>String</code>,也可以是数字，包括整数，浮点数和二进制数。</p>
<p>主要的应用有：缓存，计数（比如用户的访问次数、热点文章的点赞转发数量等等），共享<code>session</code>和限速。</p>
<p>内部编码主要有：</p>
<ul>
<li><code>int</code>:8个字节的长整型</li>
<li><code>embstr</code>:小于等于39个字节的字符串</li>
<li><code>raw</code>:大于39个字节的字符</li>
</ul>
<h3 id="各个指令的时间复杂度"><a href="#各个指令的时间复杂度" class="headerlink" title="各个指令的时间复杂度"></a>各个指令的时间复杂度</h3><h4 id="单数据操作O-1"><a href="#单数据操作O-1" class="headerlink" title="单数据操作O(1)"></a>单数据操作O(1)</h4><ul>
<li><strong>set</strong>：为一个 key 设置 value，可以配合 EX/PX 参数指定 key 的有效期，通过 NX/XX 参数针对 key 是否存在的情况进行区别操作，时间复杂度 <code>O(1)</code></li>
<li><strong>get</strong>：获取某个 key 对应的 value，时间复杂度 <code>O(1)</code></li>
<li><strong>getset</strong>：为一个 key 设置 value，并返回该 key 的<strong>原 value</strong>，时间复杂度 <code>O(1)</code></li>
</ul>
<h4 id="多数据操作O-N"><a href="#多数据操作O-N" class="headerlink" title="多数据操作O(N)"></a>多数据操作O(N)</h4><ul>
<li><strong>mset</strong>：为多个 key 设置 value，时间复杂度 <code>O(N)</code></li>
<li><strong>msetnx</strong>：同 MSET，如果指定的 key 中有任意一个已存在，则不进行任何操作，时间复杂度 <code>O(N)</code></li>
<li><strong>mget</strong>：获取多个 key 对应的 value，时间复杂度 <code>O(N)</code></li>
</ul>
<h4 id="自增-减O-1"><a href="#自增-减O-1" class="headerlink" title="自增/减O(1)"></a>自增/减O(1)</h4><ul>
<li><strong>incr</strong>：将 key 对应的 value 值自增1，并返回自增后的值。只对可以<strong>转换为整型</strong>的 String 数据起作用。时间复杂度 <code>O(1)</code></li>
<li><strong>incrby</strong>：将 key 对应的 value 值自增指定的整型数值，并返回自增后的值。只对可以转换为整型的 String 数据起作用。时间复杂度 <code>O(1)</code></li>
<li><strong>decr/decrby</strong>：同 INCR/INCRBY，自增改为自减。</li>
</ul>
<a id="more"></a>

<h2 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h2><p><code>Hash</code>是一个<code>string</code>类型的<code>field</code>和<code>value</code>的映射表，<code>hash</code>特别适合用于<strong>存储对象</strong>，后续操作的时候，可以直接仅仅修改这个对象某个字段的值。比如可以用<code>hash</code>数据结构来存储用户信息，商品信息等</p>
<img src="https://csn.damyoung.cn/image-20201027234850342.png" alt="image-20201027234850342" style="zoom:80%;" />

<p>应用：电商网站购物车</p>
<img src="https://csn.damyoung.cn/image-20201030165358794.png" alt="image-20201030165358794" style="zoom:80%;" />

<p>内部编码主要：</p>
<ul>
<li><code>ziplist</code>(<strong>压缩列表</strong>)：当哈希类型元素个数小于<code>hash-max-ziplist-entries</code>配置（默认512个字节），同时所有值小于<code>hash-max-ziplist-value</code>配置（默认64个字节）时，使用<code>ziplist</code>作为内部实现，<code>ziplist</code>使用更加紧凑的结构实现多个元素的连续存储，在节省内存方面更加优秀</li>
<li><code>hashtable</code>(<strong>哈希表</strong>)：当哈希类型无法满足<code>ziplist</code>的条件时，使用<code>hashtable</code>作为内部实现，因为此时<code>ziplist</code>读写效率会下降，而<code>hashtable</code>读写时间复杂度为O(1)</li>
</ul>
<h3 id="各个指令的时间复杂度-1"><a href="#各个指令的时间复杂度-1" class="headerlink" title="各个指令的时间复杂度"></a>各个指令的时间复杂度</h3><p>与 Hash 相关的常用命令：</p>
<ul>
<li><strong>hset</strong>：将 key 对应的 Hash 中的 field 设置为 value。如果该 Hash 不存在，会自动创建一个。时间复杂度 <code>O(1)</code></li>
<li><strong>hget</strong>：返回指定 Hash 中 field 字段的值，时间复杂度 <code>O(1)</code></li>
<li><strong>hsetnx</strong>：同 HSET，但如 field 已经存在，HSETNX 不会进行任何操作，时间复杂度 <code>O(1)</code></li>
<li><strong>hexists</strong>：判断指定Hash中 field 是否存在，存在返回1，不存在返回0，时间复杂度 <code>O(1)</code></li>
<li><strong>HMSET/HMGET</strong>：同 HSET 和 HGET，可以批量操作同一个 key 下的多个 field，时间复杂度：<code>O(N)</code>，N为一次操作的 field 数量</li>
<li><strong>hdel</strong>：删除指定 Hash 中的 field（1个或多个），时间复杂度：<code>O(N)</code>，N 为操作的 field 数量</li>
<li><strong>hincrby</strong>：同 INCRBY 命令，对指定 Hash 中的一个 field 进行 INCRBY，时间复杂度 <code>O(1)</code></li>
</ul>
<p>应谨慎使用的Hash相关命令：</p>
<ul>
<li><strong>hgetall</strong>：返回指定 Hash 中所有的 field-value 对。返回结果为数组，数组中 field 和 value 交替出现。时间复杂度 <code>O(N)</code></li>
<li><strong>hkeys/hvals</strong>：返回指定 Hash 中所有的 field/value，时间复杂度 <code>O(N)</code></li>
</ul>
<p>上述三个命令都会对 Hash 进行完整遍历，Hash中的 field 数量与命令的耗时线性相关，对于尺寸不可预知的 Hash，应严格避免使用上面三个命令，而改为使用 HSCAN 命令进行游标式的遍历</p>
<h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><p><code>list</code>就是链表，Redis中<code>list</code>的应用场景非常多，也是Redis最重要的数据结构之一</p>
<p><code>list</code>的实现是一个双向链表，既可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。</p>
<p>应用：应用于最新消息展示，消息队列</p>
<ul>
<li>依赖list数据具有顺序的特征对信息进行管理</li>
<li>使用队列模型解决多路信息汇总合并的问题</li>
<li>使用栈模型解决最新消息的问题</li>
</ul>
<p>内部编码有：</p>
<ul>
<li><code>ziplist</code>(<strong>压缩列表</strong>)：当哈希类型元素个数小于<code>list-max-ziplist-entries</code>配置（默认512），同时所有值小于<code>list-max-ziplist-value</code>配置（默认64）时，使用<code>ziplist</code>作为内部实现，<code>ziplist</code>使用更加紧凑的结构实现多个元素的连续存储，在节省内存方面更加优秀</li>
<li><code>linkedlist</code>(<strong>链表</strong>)：当列表类型无法满足<code>ziplist</code>条件时，使用链表作为内部实现</li>
</ul>
<h3 id="各个指令的时间复杂度-2"><a href="#各个指令的时间复杂度-2" class="headerlink" title="各个指令的时间复杂度"></a>各个指令的时间复杂度</h3><ul>
<li><strong>lpush</strong>：向指定 List 的左侧（即头部）插入 1 个或多个元素，<strong>返回插入后的 List 长度</strong>。时间复杂度 <code>O(N)</code>，N 为插入元素的数量</li>
<li><strong>rpush</strong>：同 LPUSH，向指定 List 的右侧（即尾部）插入 1 或多个元素</li>
<li><strong>lpop</strong>：从指定 List 的左侧（即头部）移除一个元素并返回，时间复杂度 <code>O(1)</code></li>
<li><strong>rpop</strong>：同 LPOP，从指定 List 的右侧（即尾部）移除 1 个元素并返回</li>
<li><strong>lpushx/rpushx</strong>：与 LPUSH/RPUSH 类似，区别在于，LPUSHX/RPUSHX 操作的 key 如果不存在，则不会进行任何操作</li>
<li><strong>llen</strong>：返回指定 List 的长度，时间复杂度 <code>O(1)</code></li>
<li><strong>lrange</strong>：返回指定 List 中指定范围的元素（双端包含，即 <code>LRANGE key 0 10</code> 会返回 11 个元素），时间复杂度 <code>O(N)</code>。应尽可能控制一次获取的元素数量，一次获取过大范围的 List 元素会导致延迟，同时对长度不可预知的 List，避免使用 <code>LRANGE key 0 -1</code> 这样的完整遍历操作。</li>
</ul>
<p>应谨慎使用的List相关命令：</p>
<ul>
<li><strong>lindex</strong>：返回指定 List <strong>指定 index</strong> 上的元素，如果 index 越界，返回nil。index 数值是回环的，即 -1 代表 List 最后一个位置，-2 代表 List 倒数第二个位置。时间复杂度 <code>O(N)</code></li>
<li><strong>lset</strong>：将指定 List <strong>指定 index</strong> 上的元素设置为 value，如果 index 越界则返回错误，时间复杂度 <code>O(N)</code>，如果操作的是头/尾部的元素，则时间复杂度为 <code>O(1)</code></li>
<li><strong>linsert</strong>：向指定 List 中指定元素之前/之后插入一个新元素，并返回操作后的 List 长度。如果指定的元素不存在，返回 -1。如果指定 key 不存在，不会进行任何操作，时间复杂度 <code>O(N)</code></li>
</ul>
<p>由于 Redis 的 List 是链表结构的，上述的三个命令的算法效率较低，<strong>需要对 List 进行遍历</strong>，命令的耗时无法预估，在 List 长度大的情况下耗时会明显增加，应谨慎使用。</p>
<h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><blockquote>
<p>存储大量数据，高效的查询效率，并且值不允许重复</p>
</blockquote>
<p>集合（<code>set</code>）可以保存多个字符串元素，但是不允许有重复元素，并且集合中的元素是无序的，一个集合最多可以存储<code>2^32-1</code>个元素，集合可以进行内部的增删改查和多个集合取交集，并集，差集。</p>
<p>主要的应用有：标签，生成随机数（抽奖）, 应用于随机推荐类信息检索，如热点新闻推荐等</p>
<p>​                            社交需求（共同好友，粉丝等等）</p>
<p>​                  </p>
<p>内部编码主要有：</p>
<ul>
<li><code>intset</code>(<strong>整数集合</strong>)：当集合中的元素都是整数而且元素个数小于<code>set-max-intset-entries</code>配置（默认512个）时，使用该编码减少内存的使用</li>
<li><code>hashtable</code>(<strong>哈希表</strong>)：其它条件下使用哈希表作为内部实现</li>
</ul>
<h3 id="各个指令的时间复杂度-3"><a href="#各个指令的时间复杂度-3" class="headerlink" title="各个指令的时间复杂度"></a>各个指令的时间复杂度</h3><ul>
<li><strong>sadd</strong>：向指定 Set 中添加 1 个或多个 member，如果指定 Set 不存在，会自动创建一个。时间复杂度 <code>O(N)</code>，N 为添加的 member 个数</li>
<li><strong>srem</strong>：从指定 Set 中移除 1 个或多个 member，时间复杂度 <code>O(N)</code>，N 为移除的 member 个数</li>
<li><strong>srandmember</strong>：从指定 Set 中<strong>随机返回</strong> 1 个或多个 member，时间复杂度 <code>O(N)</code>，N 为返回的 member 个数</li>
<li><strong>spop</strong>：从指定 Set 中随机<strong>移除并返回</strong> count 个 member，时间复杂度 <code>O(N)</code>，N 为移除的 member 个数</li>
<li><strong>scrad</strong>：返回指定 Set 中的 member 个数，时间复杂度 <code>O(1)</code></li>
<li><strong>sismember</strong>：判断指定的 value 是否存在于指定 Set 中，时间复杂度 <code>O(1)</code></li>
<li><strong>smove</strong>：将指定 member 从一个 Set 移至另一个 Set</li>
</ul>
<p>慎用的Set相关命令：</p>
<ul>
<li><strong>smembers</strong>：返回指定 Hash 中所有的 member，时间复杂度 <code>O(N)</code></li>
<li><strong>sunion/sunionstore</strong>：计算多个 Set 的并集并返回/存储至另一个 Set 中，时间复杂度 <code>O(N)</code>，N 为参与计算的所有集合的总 member 数</li>
<li><strong>sinter/sinterstore</strong>：计算多个 Set 的交集并返回/存储至另一个 Set 中，时间复杂度 <code>O(N)</code>，N 为参与计算的所有集合的总 member 数</li>
<li><strong>sdiff/sdiffstore</strong>：计算 1 个 Set 与 1 或多个 Set 的差集并返回/存储至另一个 Set 中，时间复杂度 <code>O(N)</code>，N 为参与计算的所有集合的总 member 数</li>
</ul>
<p>上述几个命令涉及的计算量大，应谨慎使用，特别是在参与计算的 Set 尺寸不可知的情况下，应严格避免使用。可以考虑通过 SSCAN 命令遍历获取相关 Set 的全部 member，如果需要做并集/交集/差集计算，可以在客户端进行，或在不服务实时查询请求的 Slave 上进行</p>
<h2 id="ZSet"><a href="#ZSet" class="headerlink" title="ZSet"></a>ZSet</h2><blockquote>
<p>数据排序有利于数据的有效展示，需要提供一种根据自身特征进行排序的方式</p>
<p>sorted_set类型：在set存储结构基础上添加可排序字段score</p>
</blockquote>
<img src="https://csn.damyoung.cn/image-20201031164401584.png" alt="image-20201031164401584" style="zoom:80%;" />

<p>应用：排行榜系统，用户点赞。需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。</p>
<p>内部编码实现：</p>
<ul>
<li><code>ziplist</code>(<strong>压缩列表</strong>)：当哈希类型元素个数小于<code>zset-max-ziplist-entries</code>配置（默认128个），同时所有值小于<code>zset-max-ziplist-value</code>配置（默认64）时，使用<code>ziplist</code>作为内部实现，<code>ziplist</code>使用更加紧凑的结构实现多个元素的连续存储，在节省内存方面更加优秀。</li>
<li><code>skiplist</code>(<strong>跳表</strong>)：当<code>ziplist</code>条件不满足时，有序集合会使用<code>skiplist</code>作为内部实现，因为此时<code>ziplist</code>的读写效率会下降</li>
</ul>
<h3 id="各个指令的时间复杂度-4"><a href="#各个指令的时间复杂度-4" class="headerlink" title="各个指令的时间复杂度"></a>各个指令的时间复杂度</h3><ul>
<li><strong>zadd</strong>：向指定 Sorted Set 中添加 1 个或多个 member，时间复杂度 <code>O(Mlog(N))</code>，M 为添加的 member 数量，N 为 Sorted Set 中的 member 数量</li>
<li><strong>zrem</strong>：从指定 Sorted Set 中删除 1 个或多个 member，时间复杂度 <code>O(Mlog(N))</code>，M 为删除的 member 数量，N 为 Sorted Set 中的 member 数量</li>
<li><strong>zcount</strong>：返回指定 Sorted Set 中指定 <strong>score 范围内</strong>的 member 数量，时间复杂度：<code>O(log(N))</code></li>
<li><strong>zcrad</strong>：返回指定 Sorted Set 中的 member 数量，时间复杂度 <code>O(1)</code></li>
<li><strong>zscore</strong>：返回指定 Sorted Set 中指定 member 的 score，时间复杂度 <code>O(1)</code></li>
<li><strong>zrank/zrevrank</strong>：返回指定 member 在 Sorted Set 中的排名，ZRANK 返回按升序排序的排名，ZREVRANK 则返回按降序排序的排名。时间复杂度 <code>O(log(N))</code></li>
<li><strong>zincrby</strong>：同 INCRBY，对指定 Sorted Set 中的指定 member 的 score 进行自增，时间复杂度 <code>O(log(N))</code></li>
</ul>
<p>慎用的Sorted Set相关命令：</p>
<ul>
<li><strong>zrange/zrevrange</strong>：返回指定 Sorted Set 中指定排名范围内的所有 member，ZRANGE 为按 score 升序排序，ZREVRANGE 为按 score 降序排序，时间复杂度 <code>O(log(N)+M)</code>，M为本次返回的 member 数</li>
<li><strong>ZRANGEBYSCORE/ZREVRANGEBYSCORE</strong>：返回指定 Sorted Set 中指定 score 范围内的所有 member，返回结果以升序/降序排序，min 和 max 可以指定为 -inf和+ inf，代表返回所有的 member。时间复杂度 <code>O(log(N)+M)</code></li>
<li><strong>ZREMRANGEBYRANK/ZREMRANGEBYSCORE</strong>：移除 Sorted Set 中指定排名范围/指定 score 范围内的所有 member。时间复杂度 <code>O(log(N)+M)</code></li>
</ul>
<p>上述几个命令，应尽量避免传递 <code>[0 -1]</code> 或 <code>[-inf +inf]</code> 这样的参数，来对 Sorted Set 做一次性的完整遍历，特别是在 Sorted Set 的尺寸不可预知的情况下。可以通过 ZSCAN 命令来进行游标式的遍历，或通过 LIMIT 参数来限制返回 member 的数量（适用于 ZRANGEBYSCORE 和 ZREVRANGEBYSCORE 命令），以实现游标式的遍历。</p>
<h1 id="3、持久化"><a href="#3、持久化" class="headerlink" title="3、持久化"></a>3、持久化</h1><p>Redis支持两种持久化方案，分别是<strong>RDB（快照）</strong>和<strong>AOF（只追加文件）</strong></p>
<blockquote>
<p>将当前<strong>数据状态</strong>进行保存，<strong>快照</strong>形式，<strong>存储数据结果</strong>，存储格式简单， 关注点在于数据</p>
<p>将数据操作过程进行保存，<strong>日志</strong>形式，<strong>存储操作过程</strong>，存储格式复杂，关注点在于数据的操作过程</p>
</blockquote>
<p><img src="https://csn.damyoung.cn/image-20201101105329319.png" alt="image-20201101105329319" style="zoom:80%;" /><img src="https://csn.damyoung.cn/image-20201101111813388.png" alt="image-20201101111813388" style="zoom: 80%;" /></p>
<h2 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h2><p>Redis可以通过创建快照来获得存储在内存里面的数据<strong>在某个时间点上的副本</strong>。</p>
<ul>
<li><p>Redis创建快照之后，可以对快照进行备份</p>
</li>
<li><p>可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能）</p>
</li>
<li><p>还可以将快照留在原地以便重启服务器的时候使用。快照持久化是Redis默认采用的持久化方式。</p>
</li>
</ul>
<h3 id="触发机制"><a href="#触发机制" class="headerlink" title="触发机制"></a>触发机制</h3><h4 id="手动触发"><a href="#手动触发" class="headerlink" title="手动触发"></a>手动触发</h4><ul>
<li><code>save</code>:阻塞当前Redis，直到RDB过程完成，对于内存比较大的实例会造成阻塞，已经被淘汰</li>
<li><code>bgsave</code>:Redis进行执行<code>fork</code>操作创建子进程，RDB持久化过程由子进程完成，完成后自动结束，阻塞只发生在<code>fork</code>阶段，一般时间很短。</li>
</ul>
<h4 id="自动触发"><a href="#自动触发" class="headerlink" title="自动触发"></a>自动触发</h4><ol>
<li><p>使用<code>save</code>相关配置，会自动出发<code>bgsave</code>,在<code>redis.conf</code>配置文件中默认有此下配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line"></span><br><span class="line">save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line"></span><br><span class="line">save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br></pre></td></tr></table></figure>


</li>
</ol>
<ol start="2">
<li><p>如果从节点执行全量复制操作，主节点自动执行<code>bgsave</code>生成RDB文件并发送给从节点</p>
</li>
<li><p>执行<code>debug reload</code>命令时重新加载Redis时，也会自动触发<code>save</code>操作</p>
</li>
<li><p>默认情况下执行<code>shutdown</code>命令，如果没有开启AOF持久化功能则自动执行<code>bgsave</code></p>
</li>
</ol>
<h3 id="bsave流程"><a href="#bsave流程" class="headerlink" title="bsave流程"></a>bsave流程</h3><ol>
<li><p>执行bsave命令，Redis父线程判断当前是否存在正在执行的子进程，如果RDB/AOF子进程存在直接返回</p>
</li>
<li><p>父进程执行fork操作创建子进程，fork操作过程父进程会阻塞，通过<code>info status</code>命令中<code>latest_fork_usec</code>选项，获得最近一个fork操作的耗时</p>
</li>
<li><p>父进程fork完成后，<code>bsave</code>命令<code>background saving start</code>信息不再阻塞父进程，可以继续响应其他命令</p>
</li>
<li><p>子进程创建RDB文件，根据父进程内存生成的临时快照文件，完成后对原有文件进行原子替换，执行<code>lastsave</code>可以获取最后一次生成RDB的事件，对应info统计的<code>rdb_last_save_time</code></p>
</li>
<li><p>进程发送信号给父进程表示完成，父进程更新统计信息，存放在<code>info</code>的<code>Pesistence</code>下</p>
</li>
</ol>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li>RDB是一个紧凑压缩的二进制文件，代表Redis在某个时间点上的一个数据快照，非常适用于备份，全量复制等场景</li>
<li>Redis加载RDB恢复数据远远快于AOF的方式</li>
</ul>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>没法做到实时持久化/秒级持久化</li>
<li>RDB使用特定的二进制格式保存，Redis演变过程中有很多RDB版本，存在老版本无法兼容新版本的问题</li>
<li>如果数据量很大，保存快照的时间会很长。</li>
</ul>
<h2 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h2><p>以独立日志的方式记录每次写命令，将写命令添加到 AOF 文件（Append Only File）的末尾。重启时再重新执行AOF文件中的命令达到恢复数据的目的。</p>
<p>AOF的主要作用是解决数据持久化的<strong>实时性</strong>，因此已成为主流的持久化方案。</p>
<p>默认情况下Redis没有开启AOF方式的持久化，可以通过以下配置开启：</p>
   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes</span><br></pre></td></tr></table></figure>
<p>开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是<code>appendonly.aof</code>。</p>
<h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><ol>
<li>写入命令(<code>append</code>):所有的写入命令都会追加到<code>aof_buf</code>缓冲区</li>
<li>文件同步(<code>aync</code>):AOF缓冲区根据对应的策略向硬盘做同步操作</li>
<li>文件重写(<code>rewrite</code>):随着AOF文件越来越大，定期对AOF文件进行重写，达到压缩的目的</li>
<li>重启加载(<code>load</code>):当Redis服务器重启时，可以加载AOF文件进行数据恢复</li>
</ol>
<p>在Redis的配置文件中存在三种不同的 AOF 持久化同步策略，它们分别是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度</span><br><span class="line">appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘</span><br><span class="line">appendfsync no        #让操作系统决定何时进行同步</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>always</strong>：写入<code>aof_buf</code>后调用系统<code>fsync</code>操作同步到AOF文件，<code>fsync</code>完成后线程返回；每次写入都要进行文件同步，严重降低Redis速度，一般不建议使用</li>
<li><strong>everysec</strong>：命令写入<code>aof_buf</code>后调用系统<code>write</code>操作，完成后线程返回。<code>fsync</code>同步文件操作由专门线程每秒调用一次；建议的策略，<strong>理论上在系统突然宕机的情况下会丢失1秒数据</strong>，<code>fsync</code>完成后会与上次<code>fsync</code>时间做对比，超过两秒后主线程阻塞，直到同步操作完成,<strong>因此最多可能丢失2秒数据，不是1秒</strong></li>
<li><code>no</code>:命令写入<code>aof_buf</code>后调用系统<code>write</code>操作，不对AOF文件做<code>fsync</code>同步，同步硬盘操作由操作系统负责，通常同步周期最长30秒，周期不可控，加大每次同步的数据量，虽然提升了性能，安全性无法保证</li>
</ul>
<h3 id="Redis-4-0-对于持久化机制的优化"><a href="#Redis-4-0-对于持久化机制的优化" class="headerlink" title="Redis 4.0 对于持久化机制的优化"></a>Redis 4.0 对于持久化机制的优化</h3><p>Redis 4.0 开始支持 RDB 和 AOF 的<strong>混合持久化</strong>（默认关闭，可以通过配置项<code>aof-use-rdb-preamble</code>开启）。</p>
<p>如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。</p>
<h3 id="AOF重写机制"><a href="#AOF重写机制" class="headerlink" title="AOF重写机制"></a>AOF重写机制</h3><p>随着命令不断写入AOF，文件会越来越大，Redis引入重写机制压缩文件体积，AOF文件重写是把Redis进程内的数据转化为写命令同步到新AOF文件的过程<br>重写后AOF文件变小的原理：</p>
<ul>
<li>进程内已经超时的数据不再写入文件</li>
<li>旧的AOF文件含有无效命令，如<code>del key</code>，<code>hdel key2</code>，<code>srem keys</code>，<code>set a1</code>，<code>set a2</code>等，重写时使用进程内的数据直接生成，这样新的AOF文件只保留最终数据的写入命令</li>
<li>多条写的命令合并为一条，如<code>lpush list a</code>，<code>lpush list b</code>转化为<code>lpush list a b</code>，为了防止过多造成客户端缓冲区溢出，以64个元素为界拆分多条</li>
</ul>
<p><strong>重写的优点</strong>：降低文件占用空间，更快的被Redis加载</p>
<h4 id="重写过程的触发"><a href="#重写过程的触发" class="headerlink" title="重写过程的触发"></a>重写过程的触发</h4><ul>
<li><strong>手动触发</strong>：使用<code>bgrewriteaof</code>命令                                                                                 </li>
<li></li>
<li><strong>自动触发</strong>：配置文件配置<code>auto-aof-rewrite-min-size</code>,<code>auto-aof-rewrite-percentage</code>,前者表示AOF重写时文件最小体积，默认64MB，后者代表AOF文件空间（<code>aof_current_size</code>）和上一次重写后AOF文件空间（<code>aof_base_size</code>）的比值</li>
</ul>
<h4 id="重写流程"><a href="#重写流程" class="headerlink" title="重写流程"></a>重写流程</h4><ol>
<li>执行AOF重写请求，如果当前进程正在执行AOF重写，请求不执行；如果当前进程正在执行<code>bgsave</code>操作，重写命令延迟到<code>bgsave</code>完成之后再执行</li>
<li>父进程执行fork创建子进程，开销等同于<code>bgsave</code></li>
<li>(1).主进程<code>fork</code>操作完成后，继续响应其他命令，所有修改命令依然写入AOF缓冲区并根据<code>appendfsync</code>策略同步到硬盘，保证原有AOF机制正确性<br>(2).由于<code>fork</code>操作运用写时复制技术，子进程只能共享<code>fork</code>操作时的内部数据。由于父进程依然响应命令，Redis使用<strong>AOF重写缓冲区</strong>保证这部分新数据，防止新的AOF文件生成期间丢失这部分数据</li>
<li>子进程根据内存快照，按照命令合并规则写入到新的AOF文件，每次批量写入硬盘数据量由配置<code>aof-rewrite-incremental-fsync</code>控制，默认32MB，防止单次刷盘数据过多造成硬盘阻塞</li>
<li>(1). 新AOF文件写入完成后，子进程发送信号给父进程，父进程更新统计信息<br>(2). 父进程把AOF重写缓冲区的数据写入到新的AOF文件<br>(3). 使用新的AOF文件替换老文件，重写完成</li>
</ol>
<h1 id="4、事务"><a href="#4、事务" class="headerlink" title="4、事务"></a>4、事务</h1><p>Redis提供了简单的事务功能，将一组需要执行的命令放到<code>multi</code>和<code>exec</code>之间，<code>multi</code>代表事务开始，<code>exec</code>代表事务结束，只有执行了<code>exec</code>后中间的命令才会被执行</p>
<p>如果要停止事务的执行，可以使用<code>discard</code>命令代替<code>exec</code></p>
<p>事务中出现错误的情况：</p>
<ul>
<li><strong>命令错误</strong>：例如语法错误，会导致整个事务无法执行</li>
<li><strong>运行时错误</strong>：例如错将<code>sadd</code>写成<code>zadd</code>，这时候执行<code>exec</code>时<strong>正确的命令会被执行，Redis不支持回滚功能</strong></li>
</ul>
<p>在事务之前如果需要确保事务中的<code>key</code>没有被其他客户端修改才能执行，否则不执行（乐观锁），可以通过在<code>multi</code>之前先执行<code>watch</code>命令来实现</p>
<p><strong>Redis事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。</strong></p>
<p>在传统的关系式数据库中，常常用 ACID 性质来检验事务功能的可靠性和安全性。在 Redis 中，事务总是具有原子性（Atomicity）、一致性（Consistency）和隔离性（Isolation），并且当 Redis 运行在某种特定的持久化模式下时，事务也具有持久性（Durability）。</p>
<h1 id="5、缓存问题"><a href="#5、缓存问题" class="headerlink" title="5、缓存问题"></a>5、缓存问题</h1><h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><p>缓存雪崩指的是缓存同一时间大面积的失效，所以后面的请求都会落到数据库上，造成数据库短时间内承受大量的请求而崩掉。</p>
<p>解决方案：</p>
<ul>
<li>事前：尽量保证整个Redis集群的高可用性，发现机器宕机尽快补上，选择合适的内存淘汰策略</li>
<li>事中：<strong>本地ehcache缓存+hystrix限流&amp;降级</strong>，避免MySQL崩掉</li>
<li>事后：利用redis持久化机制保存的数据尽快恢复缓存</li>
</ul>
<p><img src="http://qiniu.xiaoming.net.cn/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.jpeg" alt="缓存雪崩解决方案"></p>
<p><strong>针对 Redis 服务不可用的情况：</strong></p>
<ol>
<li>采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。</li>
<li>限流，避免同时处理大量的请求。</li>
</ol>
<p><strong>针对热点缓存失效的情况：</strong></p>
<ol>
<li>设置不同的失效时间比如随机设置缓存的失效时间。</li>
<li>缓存永不失效。</li>
</ol>
<h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。</p>
<h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><h4 id="参数校验"><a href="#参数校验" class="headerlink" title="参数校验"></a>参数校验</h4><p>最基本的就是首先做好<strong>参数校验</strong>，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。</p>
<h4 id="缓存无效-key"><a href="#缓存无效-key" class="headerlink" title="缓存无效 key"></a>缓存无效 key</h4><p>如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： <code>SET key value EX 10086</code> 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。</p>
<h4 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h4><p>将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。</p>
<p>具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。</p>
<p>流程如下：</p>
<p><img src="http://qiniu.xiaoming.net.cn/%E5%8A%A0%E5%85%A5%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E5%90%8E%E7%9A%84%E7%BC%93%E5%AD%98%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png" alt="加入布隆过滤器后的缓存处理流程"></p>
<p>但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： <strong>布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。</strong></p>
<h4 id="缓存空结果"><a href="#缓存空结果" class="headerlink" title="缓存空结果"></a>缓存空结果</h4><p>另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。</p>
<h1 id="6、主从复制"><a href="#6、主从复制" class="headerlink" title="6、主从复制"></a>6、主从复制</h1><h2 id="建立复制"><a href="#建立复制" class="headerlink" title="建立复制"></a>建立复制</h2><p>方法有三种：</p>
<ol>
<li>在配置文件中加入<code>slaveof &#123;masterHost&#125; &#123;masterPort&#125;</code>,随Redis启动生效</li>
<li>在<code>redis-server</code>启动命令后加入<code>--slaveof &#123;masterHost&#125; &#123;masterPort&#125;</code>生效</li>
<li>直接使用命令：<code>slaveof &#123;masterHost&#125; &#123;masterPort&#125;</code>生效</li>
</ol>
<blockquote>
<p><strong>slaveof</strong>命令指定主节点，并将当前节点设置为从节点，建立成功后，从节点会复制主节点的数据。</p>
</blockquote>
<h2 id="复制过程"><a href="#复制过程" class="headerlink" title="复制过程"></a>复制过程</h2><ol>
<li><p><strong>保存主节点信息</strong>：执行<code>slaveof</code>后从节点只保存主节点的地址信息便直接返回，还未建立复制的完整流程</p>
</li>
<li><p><strong>主从建立socket连接</strong>:从节点内部通过每秒运行的定时任务维护复制的相关逻辑，当定时任务发现存在新的主节点后，会尝试与该节点建立网络连接（通过建立socket套接字，接受主节点发送的复制命令）。如果从节点无法建立连接，定时任务会无限重试直到连接成功或者执行<code>slaveof no one</code></p>
</li>
<li><p><strong>发送<code>ping</code>命令</strong>:连接建立成功后，从节点发送ping命令请求首次通信，检测主从之间网络套接字是否可用，同时检测主节点当前是否可接受处理命令。如果发送<code>ping</code>命令后，从节点没有收到主节点的pong回复或者超时，比如网络超时或者主节点正在阻塞无法响应命令，从节点会断开复制连接，下次定时任务会发起重连</p>
</li>
<li><p><strong>权限验证</strong>：如果主节点设置了<code>requirepass</code>参数，则需要密码验证，从节点必须配置<code>masterauth</code>参数保证与主节点相同的密码才能通过验证；如果验证失败复制将终止，从节点重新发起复制流程。</p>
</li>
<li><p><strong>同步数据集</strong>:主从复制连接正常通信后，对于首次建立复制的场景，主节点会把持有的数据全部发送给从节点，这部分操作是耗时最长的步骤。Redis在2.8版本以后采用新复制命令<code>psync</code>进行数据同步，原来的<code>sync</code>命令依然支持，保证新旧版本的兼容性。新版同步划分两种情况：全量同步和部分同步。</p>
</li>
<li><p>命令持续复制</p>
<p>：当主节点把当前的数据同步给从节点后，便完成了复制的建立流程。接下来主节点会持续地把写命令发送给从节点，保证主从数据一致性。</p>
<blockquote>
<p>写命令的发送过程是异步完成，也就是说主节点自身处理完写命令后直接返回给客户端，并不等待从节点复制完成。这就会造成从节点的数据相对主节点存在延迟，具体延迟多少字节，可以通过在主节点执行<code>info replication</code>命令查看。</p>
</blockquote>
</li>
</ol>
<h2 id="主从复制下数据同步方法"><a href="#主从复制下数据同步方法" class="headerlink" title="主从复制下数据同步方法"></a>主从复制下数据同步方法</h2><blockquote>
<p>2.8以后Redis使用 psync 命令完成主从数据复制，数据同步过程分为全量复制和部分复制</p>
</blockquote>
<ul>
<li>全量复制：一般用于初次复制场景，Redis早期支持的复制功能只有全量复制，它会把主节点全部数据一次性发送给从节点，当数据量较大时，会对主从节点和网络造成很大的开销。</li>
<li>部分复制：用于处理在主从复制中因网络闪断等原因造成的数据丢失场景，当从节点再次连上主节点后，如果条件允许，主节点会补发丢失数据给从节点。因为补发的数据远远小于全量数据，可以有效避免全量复制的过高开销。<br>psync命令运行需要一下组件：</li>
</ul>
<ol>
<li>主从节点各自复制偏移量</li>
<li>主节点复制积压缓冲区</li>
<li>主节点运行id</li>
</ol>
<p>部分复制流程如下：</p>
<ol>
<li>当主从节点之间网络出现中断时，如果超过 repl-timeout 时间，主节点会认为从节点故障并中断复制连接。<ol>
<li>主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内部存在的复制积压缓冲区，依然可以保存最近一段时间的写命令数据，默认最大缓存1MB。</li>
</ol>
</li>
<li>当主从节点网络恢复后，从节点会再次连上主节点.</li>
<li>当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行ID。因此会把它们当作psync 参数发送给主节点，要求进行部分复制操作。</li>
<li>主节点接到 psync 命令后首先核对参数 runId 是否与自身一致，如果一致，说明之前复制的是当前主节点；之后根据参数 offset 在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送 +CONTINUE 响应，表示可以进行部分复制。</li>
<li>主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。</li>
</ol>
<h1 id="7、哨兵模式"><a href="#7、哨兵模式" class="headerlink" title="7、哨兵模式"></a>7、哨兵模式</h1><p>Redis 哨兵（Sentinel）是Redis提供的一种高可用实现方案，Redis在主从复制下，一旦主节点出现问题，需要人工干预，手动将一个从节点更新为主节点（slaveof no one），同时还要通知应用方新的主节点，让其他从节点去复制新的从节点。这种方式存在弊端大，Redis Sentinel高可用方案就是为了解决这种问题。</p>
<p>Redis Sentinel 是一个分布式架构，其中包含若干个Sentinel节点和Redis数据节点，每个Sentinel节点会对数据节点和其余Sentinel节点进行监控，当它发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它还会和其他Sentinel节点进行“协商”，当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移的工作，同时会将这个变化实时通知给Redis应用方。</p>
<h2 id="部署方式"><a href="#部署方式" class="headerlink" title="部署方式"></a>部署方式</h2><ul>
<li><p>首先部署主节点和从节点</p>
</li>
<li><p>部署sentinel节点<br>在Redis安装目录下有一个 sentinel.conf 的文件，是默认的 sentinel 节点配置文件，对其进行复制和修改</p>
</li>
<li><p>启动Sentinel节点</p>
<blockquote>
<p>Sentinel节点默认的端口是26379</p>
</blockquote>
</li>
</ul>
<p>启动节点的方式有两种：</p>
<ol>
<li><p>使用redis-sentinel命令</p>
<p>redis-sentinel sentinel配置文件.conf</p>
</li>
<li><p>使用redis-server命令加上–sentinel参数</p>
<p>redis-server sentinel配置文件.conf —sentinel</p>
<blockquote>
<p>每个sentinel节点会对主节点和所有从节点进行监控，同时Sentinel节点之间也会相互监控</p>
</blockquote>
</li>
</ol>
<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><h3 id="三个定时任务"><a href="#三个定时任务" class="headerlink" title="三个定时任务"></a>三个定时任务</h3><p>Redis Sentinel通过三个定时监控任务完成对每个节点发现和监控：</p>
<ol>
<li><p>每隔10秒，每个Sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构，Sentinel节点可以通过info replication的结果进行解析找到相应的从节点。</p>
<blockquote>
<p><strong>作用</strong>：通过向主节点执行 info 命令，获取从节点的信息，这也是为什么 Sentinel 节点不需要显式配置监控从节点<br>当有新的从节点加入时都可以立刻感知出来。<br>节点不可达或者故障转移后，可以通过 info 命令实时更新节点拓扑信息。</p>
</blockquote>
</li>
<li><p>每隔2秒，每个Sentinel会向Redis数据节点的</p>
<p><strong>sentinel</strong>:hello频道发送该 Sentinel 节点的信息，同时每个 Sentinel 节点也会订阅该频道，来了解其他 Sentinel 节点以及他们对主节点的判断</p>
<blockquote>
<p><strong>作用</strong>：发现新的Sentinel节点：通过订阅主节点的 <code>__sentinel__：hello</code> 了解其他的Sentinel节点信息，如果是新加入的 Sentinel 节点，将该 Sentinel 节点信息保存起来，并与该 Sentinel 节点创建连接<br>Sentinel 节点之间交换主节点的状态，作为后面客观下线以及领导者选举的依据。</p>
</blockquote>
</li>
<li><p>每隔1秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点发送一条ping命令做一次心跳检测，来确认这些节点当前是否可达。</p>
<blockquote>
<p><strong>作用</strong>：通过对上面的定时任务，Sentinel 节点对主节点、从节点，其余 Sentinel 节点都建立起连接，实现对每个节点的监控，这个定时任务是节点失败判定的重要依据。</p>
</blockquote>
</li>
</ol>
<h3 id="主观下线和客观下线"><a href="#主观下线和客观下线" class="headerlink" title="主观下线和客观下线"></a>主观下线和客观下线</h3><p>每个 Sentinel 节点每隔1秒对主节点、从节点、其他Sentinel节点发送ping命令做心脏检测，当这些节点超过 down-after-milliseconds 没有进行有效恢复时，Seintinel 节点会对该节点做失败判定，这个行为称为<strong>主观下线</strong>。</p>
<p>当 Sentinel 主观下线的节点是主节点时，该 Sentinel 节点会通过 <code>sentinel is-master-down-by-addr</code> 命令向其他 Sentinel 节点询问对主节点的判断。当超过 quorum 个数 Sentinel 节点认为主节点确实有问题，这时就会做出<strong>客观下线</strong>的决定</p>
<h3 id="领导者Sentinel节点的选取"><a href="#领导者Sentinel节点的选取" class="headerlink" title="领导者Sentinel节点的选取"></a>领导者Sentinel节点的选取</h3><ol>
<li>每个在线的Sentinel节点都有资格成为领导者，当它确认主节点主观下线时候，会向其他Sentinel节点发送 <code>sentinel is-master-down-by-addr</code> 命令， 要求将自己设置为领导者。</li>
<li>收到命令的Sentinel节点，如果没有同意过其他 Sentinel 节点的 <code>sentinel is-master-down-by-addr</code> 命令，将同意该请求，否则拒绝。</li>
<li>如果该 Sentinel 节点发现自己的票数已经大于等于 <code>max（quorum， num（sentinels）/2+1）</code>，那么它将成为领导者。</li>
<li>如果此过程没有选举出领导者，将进入下一次选举。</li>
</ol>
<blockquote>
<p>事实上每个Sectinel只有一票，会最先给发起请求的节点。基本上谁先完成客观下线，就会成为领导者</p>
</blockquote>
<h3 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h3><ol>
<li>在从节点列表中选出一个节点作为新的主节点，选择方法如下：</li>
</ol>
<ul>
<li>过滤：“不健康”（主观下线、断线）、5秒内没有回复过Sentinel节点ping响应、与主节点失联超过 <code>down-after-milliseconds*10</code> 秒。</li>
<li>选择slave-priority（从节点优先级）最高的从节点列表，如果存在则返回，不存在则继续。</li>
<li>选择复制偏移量最大的从节点（复制的最完整），如果存在则返回，不存在则继续。</li>
<li>选择runid最小的从节点。</li>
</ul>
<ol>
<li>Sentinel领导者节点会对第一步选出来的从节点执行slaveof no one命令让其成为主节点。</li>
<li>Sentinel领导者节点会向剩余的从节点发送命令，让它们成为新主节点的从节点，复制规则和parallel-syncs参数有关</li>
<li>Sentinel节点集合会将原来的主节点更新为从节点，并保持着对其关注，当其恢复后命令它去复制新的主节点。</li>
</ol>
<h1 id="8、集群"><a href="#8、集群" class="headerlink" title="8、集群"></a>8、集群</h1><p>在哨兵模式中，仍然只有一个Master节点。当<strong>并发写请求</strong>较大时，哨兵模式并不能缓解写压力。</p>
<p>只有主节点才具有写能力，那如果在一个集群中，能够配置多个主节点，就是redis-cluster集群模式</p>
<h1 id="9、Redis的使用"><a href="#9、Redis的使用" class="headerlink" title="9、Redis的使用"></a>9、Redis的使用</h1><h2 id="为什么要用redis-为什么要用缓存"><a href="#为什么要用redis-为什么要用缓存" class="headerlink" title="为什么要用redis/为什么要用缓存"></a>为什么要用redis/为什么要用缓存</h2><p>主要从“高性能”和“高并发”这两个点来看待这个问题</p>
<p><strong>高性能</strong>：</p>
<p>Redis中的数据是存储在内存中的，所以读写速度非常快。假如用户第一次访问数据库中的某些数据，这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变之后，同步改变缓存中相应的数据即可。</p>
<p><strong>高并发</strong>：</p>
<p>一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 redis 的情况，redis 集群的话会更高）。</p>
<blockquote>
<p>QPS（Query Per Second）：服务器每秒可以执行的查询次数；</p>
</blockquote>
<p>直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库</p>
<h2 id="为什么使用redis而不直接在程序中使用map-guava做缓存？"><a href="#为什么使用redis而不直接在程序中使用map-guava做缓存？" class="headerlink" title="为什么使用redis而不直接在程序中使用map/guava做缓存？"></a>为什么使用redis而不直接在程序中使用map/guava做缓存？</h2><p>缓存分为本地缓存和分布式缓存，以Java为例，使用自带得<code>map</code>或者<code>guava</code>实现的是本地缓存，最主要得特点是<strong>轻量以及快速</strong>，生命周期随着JVM的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，<strong>缓存不具有一致性</strong>。</p>
<p>使用<code>redis</code>或<code>memcached</code>之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持<code>redis</code>或<code>memcached</code>服务的高可用，整个程序架构上较为复杂。</p>
<h2 id="redis和memcached的区别"><a href="#redis和memcached的区别" class="headerlink" title="redis和memcached的区别"></a>redis和memcached的区别</h2><h3 id="共同点"><a href="#共同点" class="headerlink" title="共同点"></a>共同点</h3><ol>
<li>都是基于内存的数据库，一般都用来当做缓存使用。</li>
<li>都有过期策略。</li>
<li>两者的性能都非常高。</li>
</ol>
<h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><ul>
<li><strong>Redis支持更丰富的数据类型（支持更复杂的应用场景）</strong>：Redis不仅仅支持简单的<code>k/v</code>类型的数据，同时还提供<code>list</code>,<code>hash</code>,<code>set</code>,<code>zset</code>等数据结构的存储。memcached支持简单数据类型<code>String</code>（<code>k/v</code>)。</li>
<li><strong>Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而Memcached把数据全部存在内存之中</strong></li>
<li><strong>Redis 有灾难恢复机制。</strong> 因为可以把缓存中的数据持久化到磁盘上。</li>
<li><strong>Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。</strong></li>
<li><strong>集群模式</strong>：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是redis目前是原生支持<code>cluster</code>模式的</li>
<li><strong>Memcached是多线程的，非阻塞IO复用的网络模型；Redis使用单线程的多路复用IO模型</strong>（Redis 6.0 引入了多线程 IO ）</li>
<li><strong>Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。</strong></li>
<li><strong>Memcached过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。</strong></li>
</ul>
<h2 id="Redis-为什么那么快？"><a href="#Redis-为什么那么快？" class="headerlink" title="Redis 为什么那么快？"></a>Redis 为什么那么快？</h2><p>Redis 快的原因主要有：</p>
<ul>
<li>纯内存操作：是将数据储存在内存里，结构类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)。它的绝大部分请求是纯粹的内存操作，内存响应大约100纳秒，所以他读写数据的时候都不会受到硬盘 I/O 速度的限制，所以速度极快。</li>
<li>单线程：采用单线程，保证了每个操作的原子性，也减少了线程的上下文切换和竞争，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作。</li>
<li>使用多路I/O复用模型，非阻塞IO。（这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求，减少网络 IO 的时间消耗）</li>
<li>高效的数据结构：5种数据结构都有自己的应用场景</li>
<li>合理的数据编码：根据具体使用情况使用不一样的编码（字典渐进式Rehash，跳跃表）</li>
<li>其他方面的优化：定期删除+惰性删除等</li>
</ul>
<h2 id="Redis应用场景"><a href="#Redis应用场景" class="headerlink" title="Redis应用场景"></a>Redis应用场景</h2><h3 id="热点数据"><a href="#热点数据" class="headerlink" title="热点数据"></a>热点数据</h3><p>存取数据优先从 Redis 操作，如果不存在再从文件（例如 MySQL）中操作，从文件操作完后将数据存储到 Redis 中并返回。同时有个定时任务后台定时扫描 Redis 的 key，根据业务规则进行淘汰，防止某些只访问一两次的数据一直存在 Redis 中。</p>
<p>例如使用 Zset 数据结构，存储 Key 的访问次数/最后访问时间作为 Score，最后做排序，来淘汰那些最少访问的 Key。</p>
<h3 id="会话维持-Session"><a href="#会话维持-Session" class="headerlink" title="会话维持 Session"></a>会话维持 Session</h3><p>会话维持 Session 场景，即使用 Redis 作为分布式场景下的登录中心存储应用。每次不同的服务在登录的时候，都会去统一的 Redis 去验证 Session 是否正确。但是在微服务场景，一般会考虑 Redis + JWT 做 Oauth2 模块。</p>
<p>其中 Redis 存储 JWT 的相关信息主要是留出口子，方便以后做统一的防刷接口，或者做登录设备限制等。</p>
<h3 id="分布式锁-SETNX"><a href="#分布式锁-SETNX" class="headerlink" title="分布式锁 SETNX"></a>分布式锁 SETNX</h3><p>命令格式：<code>SETNX key value</code>：当且仅当 key 不存在，将 key 的值设为 value。若给定的 key 已经存在，则 SETNX 不做任何动作。</p>
<p>超时时间设置：获取锁的同时，启动守护线程，使用 <code>expire</code> 进行定时更新超时时间。如果该业务机器宕机，守护线程也挂掉，这样也会自动过期。如果该业务不是宕机，而是真的需要这么久的操作时间，那么增加超时时间在业务上也是可以接受的，但是肯定有个最大的阈值。</p>
<p>但是为了增加高可用，需要使用多台 Redis，就增加了复杂性，就可以参考 Redlock：Redlock分布式锁</p>
<h3 id="表缓存"><a href="#表缓存" class="headerlink" title="表缓存"></a>表缓存</h3><p>Redis 缓存表的场景有黑名单、禁言表等。访问频率较高，即读高。根据业务需求，可以使用后台定时任务定时刷新 Redis 的缓存表数据。</p>
<h3 id="消息队列-list"><a href="#消息队列-list" class="headerlink" title="消息队列 list"></a>消息队列 list</h3><p>主要使用了 List 数据结构。</p>
<p>List 支持在头部和尾部操作，因此可以实现简单的消息队列。</p>
<ul>
<li>发消息：在 List 尾部塞入数据。</li>
<li>消费消息：在 List 头部拿出数据。</li>
</ul>
<p>同时可以使用多个 List，来实现多个队列，根据不同的业务消息，塞入不同的 List，来增加吞吐量。</p>
<h3 id="计数器-string"><a href="#计数器-string" class="headerlink" title="计数器 string"></a>计数器 string</h3><p>主要使用了 INCR、DECR、INCRBY、DECRBY 方法。</p>
<p>INCR key：给 key 的 value 值增加一 DECR key：给 key 的 value 值减去一</p>
<h1 id="10、Redis时效性"><a href="#10、Redis时效性" class="headerlink" title="10、Redis时效性"></a>10、Redis时效性</h1><h2 id="Redis-给缓存数据设置过期时间有啥用？"><a href="#Redis-给缓存数据设置过期时间有啥用？" class="headerlink" title="Redis 给缓存数据设置过期时间有啥用？"></a>Redis 给缓存数据设置过期时间有啥用？</h2><p>一般情况下，设置保存的缓存数据的时候都会设置一个过期时间。</p>
<p>因为内存是有限的，如果缓存中的所有数据都是一直保存的话，分分钟直接Out of memory。</p>
<p>Redis 自带了给缓存数据设置过期时间的功能，比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; exp key  60 # 数据在 60s 后过期</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; ttl key # 查看数据还有多久过期</span><br><span class="line">(integer) 56</span><br></pre></td></tr></table></figure>

<p>注意：<strong>Redis中除了字符串类型有自己独有设置过期时间的命令 <code>setex</code> 外，其他方法都需要依靠 <code>expire</code> 命令来设置过期时间 。另外， <code>persist</code> 命令可以移除一个键的过期时间</strong></p>
<p><strong>过期时间除了有助于缓解内存的消耗，还有什么其他用么？</strong></p>
<p>很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在1分钟内有效，用户登录的 token 可能只在 1 天内有效。</p>
<p>如果使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多。</p>
<h2 id="Redis-判断数据过期的原理"><a href="#Redis-判断数据过期的原理" class="headerlink" title="Redis 判断数据过期的原理"></a>Redis 判断数据过期的原理</h2><p>Redis 通过一个叫做过期字典（可以看作是hash表）来保存数据过期的时间。过期字典的键指向Redis数据库中的某个key(键)，过期字典的值是一个long long类型的整数，这个整数保存了key所指向的数据库键的过期时间（毫秒精度的UNIX时间戳）。</p>
<p><img src="http://qiniu.xiaoming.net.cn/redis%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.png" alt="Redis过期时间实现原理"></p>
<p>过期字典是存储在redisDb这个结构里的：</p>
<pre><code>typedef struct redisDb &#123;
    ...
    dict *dict;     //数据库键空间,保存着数据库中所有键值对
    dict *expires   // 过期字典,保存着键的过期时间
    ...
&#125; redisDb;</code></pre>
<h2 id="redis过期键处理方式"><a href="#redis过期键处理方式" class="headerlink" title="redis过期键处理方式"></a>redis过期键处理方式</h2><p>Redis中有个设置时间过期的功能，即对存储在 redis 数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如一般项目中的<code>token</code> 或者一些登录信息，尤其是短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。</p>
<p>在<code>set key</code>的时候，都可以给一个<code>expire time</code>，就是过期时间，通过过期时间可以指定这个<code>key</code>可以存活的时间。</p>
<p>Redis对过期的键采用的删除方式是：<strong>定期删除+惰性删除</strong></p>
<ul>
<li><strong>定期删除</strong>：redis默认是每隔100ms就随机抽取一些设置了过期时间的<code>key</code>,检查其是否过期，如果过期就删除。注意这里是随机抽取的。采用随机抽取的方式是因为如果Redis存了很多<code>key</code>的话，每隔100ms就遍历所有的设置过期时间的<code>key</code>的话，就会给CPU带来很大的负载。</li>
<li><strong>惰性删除</strong>：定期删除可能会导致很多过期<code>key</code>到了时间并没有被删除掉。所以就有了惰性删除。对于过期的<code>key</code>,如果过了时间还没有被定期删除，还停留在内存中，只有在系统中查询一下这个<code>key</code>，redis才会把它给删除掉，这就是所谓的惰性删除。</li>
</ul>
<p>但是仅仅通过设置过期时间还是有问题的。如果定期删除漏掉了很多过期<code>key</code>，然后也没及时去查，也就没走惰性删除，此时会有大量过期key堆积在内存里，导致redis内存块耗尽了。redis采用<strong>内存淘汰机制</strong>进行处理。</p>
<h2 id="redis内存淘汰机制（MySQL中有2000w数据，Redis中只存了20w数据，如何保证Redis中的数据都是热点数据？）"><a href="#redis内存淘汰机制（MySQL中有2000w数据，Redis中只存了20w数据，如何保证Redis中的数据都是热点数据？）" class="headerlink" title="redis内存淘汰机制（MySQL中有2000w数据，Redis中只存了20w数据，如何保证Redis中的数据都是热点数据？）"></a>redis内存淘汰机制（MySQL中有2000w数据，Redis中只存了20w数据，如何保证Redis中的数据都是热点数据？）</h2><p>当Redis中内存使用量超出时，会施行数据淘汰策略</p>
<p>Redis支持6种淘汰策略：</p>
<ul>
<li><strong>volatile-lru</strong>：从已设置过期时间的数据集(<code>server.db[i].expires</code>)中挑选最近最少使用的数据淘汰</li>
<li><strong>volatile-ttl</strong>：从已设置过期时间的数据集(<code>server.db[i].expires</code>)中挑选将要过期的数据淘汰</li>
<li><strong>volatile-random</strong>：从已设置过期时间的数据集(<code>server.db[i].expires</code>)中任意选择数据淘汰</li>
<li><strong>allkeys-lru</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的<code>key</code>(这个是最常用的)</li>
<li><strong>allkeys-random</strong>：从数据集(<code>server.db[i].dict</code>)中任意选择数据淘汰</li>
<li><strong>no-eviction</strong>:禁止驱逐数据，也就是说当内存不足以容纳新写入的数据时，新写入操作会报错。</li>
</ul>
<p>4.0版本以后增加了以下两种：</p>
<ul>
<li><strong>volatile-lfu</strong>：从已设置过期时间的数据集(<code>server.db[i].expires</code>)中挑选最不经常使用的数据淘汰</li>
<li><strong>allkeys-lfu</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的<code>key</code></li>
</ul>
<h1 id="11、分布式锁"><a href="#11、分布式锁" class="headerlink" title="11、分布式锁"></a>11、分布式锁</h1><h2 id="如何解决Redis的并发竞争key问题"><a href="#如何解决Redis的并发竞争key问题" class="headerlink" title="如何解决Redis的并发竞争key问题"></a>如何解决Redis的并发竞争key问题</h2><p>所谓Redis的并发竞争Key的问题也就是多个系统同时对一个Key进行操作，但是最后执行的顺序和期望的顺序不同，这样也就导致了结果的不同。</p>
<p>解决方案：可以使用分布式锁（<code>Zookeeper</code>和 redis 都可以实现分布式锁）。（如果不存在Redis的并发竞争Key问题，不要使用分布式锁，这样会影响性能）</p>
<p>基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在<code>zookeeper</code>上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。</p>
<p>在实践中，当然是以可靠性为主,所以首推Zookeeper。</p>
<h2 id="Redlock分布式锁"><a href="#Redlock分布式锁" class="headerlink" title="Redlock分布式锁"></a>Redlock分布式锁</h2><p>Redis官方提出一种基于Redis实现的分布式锁的方式叫<code>Redlock</code>,这种方法比原先单节点的方法更安全。它可以保证以下特性：</p>
<ul>
<li>安全特性：互斥访问，即永远只有一个<code>client</code>能拿到锁</li>
<li>避免死锁：最终<code>client</code>都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的<code>client</code>crash了或者出现了网络分区</li>
<li>容错性：只要大部分Redis节点存活就可以正常提供服务</li>
</ul>
<h3 id="怎么在单点上实现分布式锁"><a href="#怎么在单点上实现分布式锁" class="headerlink" title="怎么在单点上实现分布式锁"></a>怎么在单点上实现分布式锁</h3><p>主要通过以下命令:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET resource_name my_random_value NX PX 30000</span><br></pre></td></tr></table></figure>

<p>该命令仅当key不存在（NX保证）时，<code>set</code>值，并且设置过期时间为<code>3000ms</code>(PX保证)，值<code>my_random_value</code>必须是所有<code>client</code>和所有锁请求发生期间唯一的，释放锁的逻辑是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if redis.call(&quot;get&quot;,KEYS[1]) &#x3D;&#x3D; ARGV[1] then</span><br><span class="line">    return redis.call(&quot;del&quot;,KEYS[1])</span><br><span class="line">else</span><br><span class="line">    return 0</span><br><span class="line">end</span><br></pre></td></tr></table></figure>

<p>上述实现避免了释放另一个<code>client</code>创建的锁，如果只有<code>del</code>命令的话，如果<code>client1</code>拿到<code>lock1</code>之后因为某些操作阻塞了很长时间，此时Redis端<code>lock1</code>已经过期了并且已经被重新分配给了<code>client2</code>,那么<code>client1</code>此时再去释放这把锁就会造成<code>client2</code>原本获取到的锁被<code>client1</code>无故释放了，但现在为每个<code>client</code>分配一个<code>unique</code>的<code>string</code>值可以避免这个问题。至于如何去生成这个<code>unique string</code>，方法很多随意选择一种就行了。</p>
<h3 id="Redlock算法"><a href="#Redlock算法" class="headerlink" title="Redlock算法"></a>Redlock算法</h3><p>假设有5个<code>master</code>节点，分布在不同的机房，为了获得锁，<code>client</code>会进行如下操作：</p>
<ol>
<li>得到当前的事件，微秒单位</li>
<li>尝试顺序的在5个实例上申请锁，当然需要使用相同的<code>key</code>和<code>random value</code>,这里一个<code>client</code>需要合理设置与<code>master</code>节点沟通的<code>timeout</code>大小，避免长时间和一个<code>fail</code>的节点浪费时间</li>
<li>当<code>client</code>在大于等于 3 个<code>master</code>上成功申请到锁的时候，且它会计算申请锁消耗了多少时间，这部分消耗的时间采用获得锁的当下时间减去第一步获得的时间戳得到，如果锁的持续时长（lock validity time）比流逝的时间多的话，那么锁就真正获取到了。</li>
<li>如果锁申请到了，那么锁真正的<code>lock validity time</code>应该是<code>origin（lock validity time） - 申请锁期间流逝的时间</code></li>
<li>如果<code>client</code>申请锁失败了，那么它就会在少部分申请成功锁的<code>master</code>节点上执行释放锁的操作，重置状态。</li>
</ol>
<blockquote>
<p>这个算法是基于一个假设：虽然不存在可以跨进程的同步时钟，但是不同进程时间都是以差不多相同的速度前进，这个假设不一定完全准确，但是和自动释放锁的时间长度相比不同进程时间前进速度差异基本是可以忽略不计的。</p>
</blockquote>
<h3 id="失败重试"><a href="#失败重试" class="headerlink" title="失败重试"></a>失败重试</h3><p>如果一个<code>client</code>申请锁失败了，那么它需要稍等一会再重试避免多个<code>client</code>同时申请锁的情况，最好的情况是一个<code>client</code>需要几乎同时向5个<code>master</code>发起申请锁申请。另外就是如果<code>client</code>申请锁失败了它需要尽快在它曾经申请到锁的<code>master</code>上执行<code>unlock</code>操作，便于其它<code>client</code>获取这把锁，避免这些锁过期造成的时间浪费，当然如果这时候网络分区使得<code>client</code>无法联系上这些<code>master</code>,那么这种浪费就是不得不付出的代价了。</p>
<h3 id="放锁"><a href="#放锁" class="headerlink" title="放锁"></a>放锁</h3><p>放锁操作很简单，就是依次释放所有节点上的锁就行了</p>
<h3 id="性能、崩溃恢复和fsync"><a href="#性能、崩溃恢复和fsync" class="headerlink" title="性能、崩溃恢复和fsync"></a>性能、崩溃恢复和fsync</h3><p>如果节点没有持久化机制，<code>client</code>从 5 个<code>master</code>中的 3 个处获得了锁，然后其中一个重启了，这时注意整个环境中又出现了 3 个<code>master</code>可供另一个<code>client</code>申请同一把锁！ 违反了互斥性。如果开启了 AOF 持久化那么情况会稍微好转一些，因为 Redis 的过期机制是语义层面实现的，所以在<code>server</code>挂了的时候时间依旧在流逝，重启之后锁状态不会受到污染。但是考虑断电之后呢，AOF部分命令没来得及刷回磁盘直接丢失了，除非配置刷回策略为<code>fsnyc = always</code>，但这会损伤性能。解决这个问题的方法是，当一个节点重启之后，规定在<code>max TTL</code>期间它是不可用的，这样它就不会干扰原本已经申请到的锁，等到它<code>crash</code>前的那部分锁都过期了，环境不存在历史锁了，那么再把这个节点加进来正常工作。</p>
<h3 id="RedLock缺陷"><a href="#RedLock缺陷" class="headerlink" title="RedLock缺陷"></a>RedLock缺陷</h3><p>需要用到锁的主要有以下两种场景考虑：</p>
<ul>
<li><strong>性能</strong>：拥有这把锁使得你不会重复劳动（例如一个job做了两次），如果这把锁fail了，两个节点同时做了这个job，那么这个job增加了你的成本</li>
<li><strong>正确性</strong>：拥有锁可以防止并发操作污染了你的系统或者数据，如果这把锁fail了，两个节点同时操作了一份数据，结果可能是数据不一致、数据丢失、file冲突等，会导致严重的后果</li>
</ul>
<h3 id="RedLock算法不可靠的场景"><a href="#RedLock算法不可靠的场景" class="headerlink" title="RedLock算法不可靠的场景"></a>RedLock算法不可靠的场景</h3><p>在分布式环境下，锁比<code>mutex</code>这类复杂，因为涉及到不同节点、网络通信并且他们随时可能无征兆的fail。假设现在有一个场景：一个client要修改一个文件，它先申请得到锁，然后修改文件写回，放锁。另一个client再申请锁。代码流程如下：</p>
<pre><code>function writeData(filename,data)&#123;
    var lock = lockService.acquireLock(filename);
    if(!lock) &#123;
        throw &#39;Failed to acquire lock!&#39;;
    &#125;

    try &#123;
        var file = storage.readFile(filename);
        var updated = updateContents(file,data);
        sotrage.writeFile(filename,updated);
    &#125;finally &#123;
        lock.release();
    &#125;
&#125;</code></pre>
<p>上述代码在以下流程中还是有可能出现bug：</p>
<p><img src="https://camo.githubusercontent.com/b1fd3e057266f0ca21f69e2a26f420f9564c5cdb/68747470733a2f2f6d617274696e2e6b6c6570706d616e6e2e636f6d2f323031362f30322f756e736166652d6c6f636b2e706e67" alt="RedLock锁流程"></p>
<p>在上述图中，得到锁的client1在持有锁的期间pause（暂停）了一段时间，例如GC停顿。锁有过期时间（一般叫租约，为了防止某个 client 崩溃之后一直占有锁），但是如果 GC 停顿太长超过了锁租约时间，此时锁已经被另一个 client2 所得到，原先的 client1 还没有感知到锁过期，这时候client再进行写时就会发生错误。即使在client1写回之前检查一下锁是否过期也无法解决这个问题，因为GC可能在任何时候发生，即使在最后的检查和写操作期间。</p>
<p>除了GC停顿，还有很多原因可能导致进程pause。例如进程可能读取尚未进入内存的数据，所以它得到一个 page fault （错误页面）并且等待 page 被加载进缓存；还有可能你依赖于网络服务；或者其他进程占用 CPU；或者其他意外发生 SIGSTOP 等。</p>
<h3 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h3><h4 id="使用Fencing（栏栅）使锁变安全"><a href="#使用Fencing（栏栅）使锁变安全" class="headerlink" title="使用Fencing（栏栅）使锁变安全"></a>使用Fencing（栏栅）使锁变安全</h4><p>在每次写操作时加入一个<code>fencing token</code>,这个场景下，<code>fencing token</code>可以是一个递增的数字（lock service可以做到），每次有client申请锁就递增一次：</p>
<p><img src="https://camo.githubusercontent.com/4ca3c6919e560b60b130c4f856d2736314713e62/68747470733a2f2f6d617274696e2e6b6c6570706d616e6e2e636f6d2f323031362f30322f66656e63696e672d746f6b656e732e706e67" alt="使用Fencing解决锁不安全问题"></p>
<p>client1 申请锁同时拿到<code>token33</code>，然后它进入长时间的停顿锁也过期了。client2 得到锁和<code>token34</code>写入数据，紧接着 client1 活过来之后尝试写入数据，自身<code>token33</code>比<code>34</code>小因此写入操作被拒绝。注意这需要存储层来检查<code>token</code>，但这并不难实现。如果使用<code>Zookeeper</code>作为<code>lock service</code>的话那么可以使用<code>zxid</code>作为递增数字。 但是<strong>对于 Redlock ，没什么生成<code>fencing token</code>的方式，并且怎么修改 Redlock 算法使其能产生<code>fencing toke</code>并不那么显而易见。因为产生<code>token</code>需要单调递增，除非在单节点<code>Redis</code>上完成但是这又没有高可靠性</strong>，需要引进一致性协议来让 Redlock 产生可靠的<code>fencing token</code>。</p>
<h4 id="使用时间来解决一致性"><a href="#使用时间来解决一致性" class="headerlink" title="使用时间来解决一致性"></a>使用时间来解决一致性</h4><p>学术界有个说法，算法对时间不做假设：因为进程可能pause一段时间、数据包可能因为网络延迟延后到达、时钟可能根本就是错的。而可靠的算法依旧要在上述假设下做正确的事情。</p>
<p>同样Redlock算法也是假设所有 Redis 节点都能对同一个 Key 在其过期前持有差不多的时间、跟过期时间相比网络延迟很小、跟过期时间相比进程 pause 很短。</p>
<h4 id="Redlock不可靠的例子"><a href="#Redlock不可靠的例子" class="headerlink" title="Redlock不可靠的例子"></a>Redlock不可靠的例子</h4><p>由于<strong>时间问题</strong>：</p>
<ol>
<li><code>client1</code>从ABC三个节点处申请到锁，DE由于网络原因请求没有到达</li>
<li>C节点的时钟往前推了（或者C崩溃了）导致lock过期</li>
<li><code>client2</code>在CDE出获得了锁，AB由于网络原因请求未到达</li>
<li>此时<code>client1</code>和<code>client2</code>都获得了锁</li>
</ol>
<p>由于<strong>进程pause而不是时钟不可靠发生的问题</strong>：</p>
<ol>
<li><code>client1</code>从ABCDE处获得了锁</li>
<li>当获得锁的<code>response</code>还没到达<code>client1</code>时<code>client1</code>进入GC停顿</li>
<li>停顿期间锁已经过期了</li>
<li><code>client2</code>在ABCDE处获得了锁</li>
<li><code>client1</code>GC完成收到了锁的<code>response</code>，此时两个<code>client</code>又拿到了同一把锁</li>
</ol>
<p>这些例子说明了，仅有在假设了一个同步性系统模型的基础上，Redlock 才能正常工作，也就是系统能满足以下属性：</p>
<ul>
<li>网络延时边界，即假设数据包一定能在某个最大延时之内到达</li>
<li>进程停顿边界，即进程停顿一定在某个最大时间之内</li>
<li>时钟错误边界，即不会从一个坏的 NTP 服务器处取得时间</li>
</ul>
<blockquote>
<p>Redlock 不是一个好的选择，对于需求性能的分布式锁应用它太重了且成本高；对于需求正确性的应用来说它不够安全。因为它对高危的时钟或者说其他上述列举的情况进行了不可靠的假设，如果应用只需要高性能的分布式锁不要求多高的正确性，那么单节点 Redis 够了；如果应用想要保住正确性，那么不建议 Redlock，建议使用一个合适的一致性协调系统，例如<code>Zookeeper</code>，且保证存在<code>fencing token</code>。</p>
</blockquote>
<h1 id="12、如何保证缓存与数据库双写时的数据一致性？"><a href="#12、如何保证缓存与数据库双写时的数据一致性？" class="headerlink" title="12、如何保证缓存与数据库双写时的数据一致性？"></a>12、如何保证缓存与数据库双写时的数据一致性？</h1><p>只要用缓存，就可能会涉及到缓存与数据库双存储，双写，只要是双写，就一定会有数据一致性问题，如何解决呢？</p>
<p>一般来说，如果系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微跟数据库偶尔有不一致的情况。</p>
<p>另外，可以将读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况，但是串行化之后，就会导致系统的吞吐量大幅度降低，需要用比正常情况下多几倍的机器去支撑线上的一个请求。</p>
<p>解决这个问题的最经典的模式，就是 Cache Aside Pattern 数据库读写模式（<strong>旁路缓存模式</strong>）。</p>
<ol>
<li>读的时候先读缓存，如果缓存不存在的话就读数据库，取出数据库后更新缓存；如果存在的话直接读取缓存的信息。</li>
<li>写的时候，先更新数据库，再删除缓存。</li>
</ol>
<h2 id="为什么是删除缓存而不是更新缓存？"><a href="#为什么是删除缓存而不是更新缓存？" class="headerlink" title="为什么是删除缓存而不是更新缓存？"></a>为什么是删除缓存而不是更新缓存？</h2><p>很多时候复杂的缓存场景，缓存不是仅仅从数据库中取出来的值。可能是关联多张表的数据并通过计算才是缓存需要的值。并且，更新缓存的代价有时候很高。<strong>对于需要频繁写操作，而读操作很少的时候，每次进行数据库的修改，缓存也要随之更新，会造成系统吞吐的下降，但此时缓存并不会被频繁访问到，用到的缓存才去算缓存</strong>。</p>
<p>删除缓存而不是更新缓存，是一种懒加载的思想，不是每次都重复更新缓存，只有用到的时候才去更新缓存，同时即使有大量的读请求，实际也就更新了一次，后面的请求不会重复读。</p>
<h2 id="Cache-Aside-Pattern存在的问题"><a href="#Cache-Aside-Pattern存在的问题" class="headerlink" title="Cache Aside Pattern存在的问题"></a>Cache Aside Pattern存在的问题</h2><p>问题：先更新数据库，再删除缓存，如果删除缓存失败了，导致数据库中是新数据，缓存中是旧数据，就出现数据不一致的问题。</p>
<p><strong>解决思路</strong>：先删除缓存，再更新数据库。</p>
<ul>
<li>缓存删除失败：如果缓存删除失败，那么就不会继续执行，数据库信息没有被修改，保持了数据的一致性；</li>
<li>缓存删除成功，数据库更新失败：此时数据库里的是旧数据，缓存是空的，查询时发现缓存不存在，就查询数据库并更新缓存，数据保持一致。</li>
</ul>
<p>问题：上面的方案存在不足，如果删除完缓存更新数据库时，如果一个请求过来查询数据，缓存不存在，就查询数据库的旧数据，更新旧数据到缓存中。随后数据更新完成，修改了数据库的数据，此时缓存和数据库的数据就会出现不一致了。高并发下会出现这种数据库 + 缓存不一致的情况。 如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。</p>
<p><strong>解决方案</strong>：采用双删除策略。写请求先删除缓存，再去更新数据库，等待一段时间后异步删除缓存。这样可以保证在读取错误数据时能及时被修正过来。</p>
<p>还有一种策略，就是：写请求先修改缓存为指定值，然后再去更新数据库，再更新缓存。读请求过来后，会先读缓存，判断是指定值后就进入循环读取状态，等到写请求更新缓存。如果循环超时就去数据库读取数据，更新缓存。</p>
<p>这种方案保证了读写的一致性，但由于读请求等待写请求的完成，会降低系统的吞吐量。</p>
<h1 id="13、Redis底层实现-用到了哪些数据结构"><a href="#13、Redis底层实现-用到了哪些数据结构" class="headerlink" title="13、Redis底层实现/用到了哪些数据结构"></a>13、Redis底层实现/用到了哪些数据结构</h1><h2 id="字典（也叫哈希）"><a href="#字典（也叫哈希）" class="headerlink" title="字典（也叫哈希）"></a>字典（也叫哈希）</h2><p>Redis 使用的是<code>key-value</code>的存储形式</p>
<p><code>dictht</code>是一个散列表结构，使用拉链法解决哈希冲突</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dictht &#123;</span><br><span class="line">    dictEntry **table;</span><br><span class="line">    unsigned long size;</span><br><span class="line">    unsigned long sizemask;</span><br><span class="line">    unsigned long used;</span><br><span class="line">&#125; dictht;</span><br><span class="line">typedef struct dictEntry &#123;</span><br><span class="line">    void *key;</span><br><span class="line">    union &#123;</span><br><span class="line">        void *val;</span><br><span class="line">        uint64_t u64;</span><br><span class="line">        ini64_t s64;</span><br><span class="line">        double d;</span><br><span class="line">    &#125; v;</span><br><span class="line">    struct dictEntry *next;</span><br><span class="line">&#125; dictEntry;</span><br></pre></td></tr></table></figure>

<p>Redis的字典<code>dict</code>中包含两个哈希表<code>dictht</code>,这是为了方便进行<code>rehash</code>操作。在扩容时，将其中一个<code>dictht</code>上的键值对<code>rehash</code>到另一个<code>dictht</code>上面，完成之后释放空间并交换两个<code>dictht</code>角色</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dict &#123;</span><br><span class="line">    dictType *type;</span><br><span class="line">    void *privdata;</span><br><span class="line">    dictht ht[2];</span><br><span class="line">    long rehashidx;</span><br><span class="line">    unsigned long iterators;</span><br><span class="line">&#125; dict;</span><br></pre></td></tr></table></figure>

<p><code>rehash</code>操作不是一次性完成的，而是采用渐进式，这是为了避免一次性执行过多的<code>rehash</code>操作给服务器造成过大的负担。</p>
<p>渐进式<code>rehash</code>通过记录<code>dict</code>的<code>rehashidx</code>完成，它从0开始，然后每执行一次<code>rehahsh</code>都会递增。例如在一次<code>rehash</code>中，要把<code>dict[0]</code> rehash 到 <code>dictht[1]</code>，这一次会把<code>dictht[0]</code>上<code>table[rehashidx]</code>的键值对<code>rehash</code>到<code>dictht[1]</code>上，<code>dictht[0]</code>的<code>table[rehashidx]</code>指向null，并令<code>rehashidx++</code>。</p>
<p>在<code>rehash</code>期间，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式<code>rehash</code>。</p>
<p>采用渐进式<code>rehash</code>会导致字典中的数据分散在两个<code>dictht</code>上，因此对字典的查找操作也需要到对应的<code>dictht</code>去执行。</p>
<h2 id="跳跃表"><a href="#跳跃表" class="headerlink" title="跳跃表"></a>跳跃表</h2><p>是有序集合的底层实现之一。</p>
<p>与红黑树相比，跳跃表有以下优点：</p>
<ul>
<li>插入速度非常快速，因为不需要进行旋转等操作来维护平衡性</li>
<li>更容易实现</li>
<li>支持无锁操作</li>
</ul>
<h1 id="14、Sorted-Set（即-ZSet-实现原理）"><a href="#14、Sorted-Set（即-ZSet-实现原理）" class="headerlink" title="14、Sorted Set（即 ZSet 实现原理）"></a>14、Sorted Set（即 ZSet 实现原理）</h1><p>ZSet 内部编码实现：</p>
<ul>
<li><code>ziplist</code>(压缩列表)：当哈希类型元素个数小于zset-max-ziplist-entries配置（默认128个），同时所有值小于zset-max-ziplist-value配置（默认64）时，使用ziplist作为内部实现，ziplist使用更加紧凑的结构实现多个元素的连续存储，在节省内存方面更加优秀。</li>
<li><code>skiplist</code>(跳表)：当ziplist条件不满足时，有序集合会使用skiplist作为内部实现，因为此时ziplist的读写效率会下降</li>
</ul>
<h2 id="ZipList"><a href="#ZipList" class="headerlink" title="ZipList"></a>ZipList</h2><p>ziplist 编码的 Zset 使用紧挨在一起的压缩列表节点来保存，第一个节点保存 member，第二个保存 score。ziplist 内的集合元素按 score 从小到大排序，其实质是一个双向链表。虽然元素是按 score 有序排序的， 但对 ziplist 的节点指针只能线性地移动，所以在 <code>REDIS_ENCODING_ZIPLIST</code> 编码的 Zset 中， 查找某个给定元素的复杂度为 O(N)。</p>
<p><img src="http://qiniu.xiaoming.net.cn/ziplist%E7%BB%93%E6%9E%84%E5%9B%BE.png" alt="ziplist结构图"></p>
<h2 id="Skiplist"><a href="#Skiplist" class="headerlink" title="Skiplist"></a>Skiplist</h2><p>skiplist 编码的 Zset 底层为一个被称为 zset 的结构体，这个结构体中<strong>包含一个字典和一个跳跃表</strong>。跳跃表按 score 从小到大保存所有集合元素，查找时间复杂度为平均 O(logN)，最坏 O(N) 。字典则保存着从 member 到 score 的映射，这样就可以用 O(1) 的复杂度来查找 member 对应的 score 值。虽然同时使用两种结构，但它们会通过指针来共享相同元素的 member 和 score，因此不会浪费额外的内存。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* zset结构体 *&#x2F;</span><br><span class="line">typedef struct zset &#123;</span><br><span class="line">    &#x2F;&#x2F; 字典，维护元素值和分值的映射关系</span><br><span class="line">    dict *dict;</span><br><span class="line">    &#x2F;&#x2F; 按分值对元素值排序序，支持O(logN)数量级的查找操作</span><br><span class="line">    zskiplist *zsl;</span><br><span class="line">&#125; zset;</span><br></pre></td></tr></table></figure>

<p><img src="http://qiniu.xiaoming.net.cn/ZSet%E4%B8%ADskiplist%E7%BB%93%E6%9E%84.png" alt="ZSet中skiplist结构"></p>
<h3 id="跳表数据结构"><a href="#跳表数据结构" class="headerlink" title="跳表数据结构"></a>跳表数据结构</h3><p>跳表查找时间复杂度为平均 O(logN)，最差 O(N)，在大部分情况下效率可与平衡树相媲美，但实现比平衡树简单的多，跳表是一种典型的以空间换时间的数据结构。</p>
<p>跳表具有以下几个特点：</p>
<ul>
<li>由许多层结构组成。</li>
<li>每一层都是一个有序的链表。</li>
<li>最底层 (Level 1) 的链表包含所有元素。</li>
<li>如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。</li>
<li>每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。</li>
</ul>
<p>跳表的查找会从顶层链表的头部元素开始，然后遍历该链表，直到找到元素大于或等于目标元素的节点，如果当前元素正好等于目标，那么就直接返回它。如果当前元素小于目标元素，那么就垂直下降到下一层继续搜索，如果当前元素大于目标或到达链表尾部，则移动到前一个节点的位置，然后垂直下降到下一层。正因为 Skiplist 的搜索过程会不断地从一层跳跃到下一层的，所以被称为跳跃表。</p>
<p><img src="https://camo.githubusercontent.com/11e7cbe718a70a81c42c37a13a257f91ef48dfd7/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d31322d392f39333636363231372e6a7067" alt="跳跃表结构"></p>
<p><img src="http://qiniu.xiaoming.net.cn/%E8%B7%B3%E8%A1%A8%E7%BB%93%E6%9E%842.png" alt="跳表结构2"></p>
<p>跳表是一个“概率型”的数据结构，指的就是跳表在插入操作时，元素的插入层数完全是随机指定的。实际上该决定插入层数的随机函数对跳表的查找性能有着很大影响，这并不是一个普通的服从均匀分布的随机数，它的计算过程如下：</p>
<ol>
<li>指定一个节点最大的层数 MaxLevel，指定一个概率 p， 层数 lvl 默认为 1 。</li>
<li>生成一个 0~1 的随机数 r，若 r &lt; p，且 lvl &lt; MaxLevel ，则执行 lvl++。</li>
<li>重复第 2 步，直至生成的 r &gt; p 为止，此时的 lvl 就是要插入的层数。</li>
</ol>
<h3 id="Skiplist-与平衡树、哈希表的比较"><a href="#Skiplist-与平衡树、哈希表的比较" class="headerlink" title="Skiplist 与平衡树、哈希表的比较"></a>Skiplist 与平衡树、哈希表的比较</h3><ul>
<li>Skiplist 和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个 key 的查找，不适宜做范围查找。</li>
<li>在做范围查找的时候，平衡树比 Skiplist 操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。</li>
<li>平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而 Skiplist 的插入和删除只需要修改相邻节点的指针，操作简单又快速。</li>
<li>从内存占用上来说，Skiplist 比平衡树更灵活一些。一般来说，平衡树每个节点包含 2 个指针（分别指向左右子树），而 Skiplist 每个节点包含的指针数目平均为1/(1−p)，具体取决于参数 p 的大小。如果像 Redis 里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。</li>
<li>查找单个 key，Skiplist 和平衡树的时间复杂度都为 O(logN)；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近 O(1)，性能更高一些。</li>
<li>从算法实现难度上来比较，Skiplist 比平衡树要简单得多。</li>
</ul>
<h3 id="Redis-中-Skiplist-的实现"><a href="#Redis-中-Skiplist-的实现" class="headerlink" title="Redis 中 Skiplist 的实现"></a>Redis 中 Skiplist 的实现</h3><p>在 Redis 的 skiplist 实现中，p=1/4 ，MaxLevel=32。</p>
<p>Redis中的 Skiplist 与经典 Skiplist 相比，有如下不同：</p>
<ul>
<li>分数(score)允许重复，即 Skiplist 的 key 允许重复，经典 Skiplist 中是不允许的。</li>
<li>在比较时，不仅比较分数（相当于 Skiplist 的 key），还比较数据本身。在 Redis 的 Skiplist 实现中，数据本身的内容唯一标识这份数据，而不是由 key 来唯一标识。另外，当多个元素分数相同的时候，还需要根据数据内容来进字典排序。</li>
<li>第 1 层链表不是一个单向链表，而是一个双向链表。这是为了方便以倒序方式获取一个范围内的元素。</li>
</ul>
<h3 id="Redis-Zset-采用跳表而不是平衡树的原因"><a href="#Redis-Zset-采用跳表而不是平衡树的原因" class="headerlink" title="Redis Zset 采用跳表而不是平衡树的原因"></a>Redis Zset 采用跳表而不是平衡树的原因</h3><ol>
<li>虽然是空间换时间，但也不是非常耗费内存，实际上取决于生成层数函数里的概率 p，取决得当的话其实和平衡树差不多。</li>
<li>因为有序集合经常会进行 ZRANGE 或 ZREVRANGE 这样的范围查找操作，跳表里面的双向链表可以十分方便地进行这类操作。</li>
<li>实现简单，ZRANK 操作还能达到 O(logN) 的时间复杂度。</li>
</ol>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>dmYang
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://dmyang-only.github.io/2020/10/17/Redis/" title="redis">https://dmyang-only.github.io/2020/10/17/Redis/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/redis/" rel="tag"># redis</a>
              <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag"># 数据库</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/10/11/02%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/" rel="prev" title="linux软件包管理">
      <i class="fa fa-chevron-left"></i> linux软件包管理
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/11/11/12%E5%B9%B6%E5%8F%91/" rel="next" title="并发">
      并发 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1%E3%80%81%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">1.</span> <span class="nav-text">1、非关系型数据库</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2%E3%80%81Redis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">2、Redis数据类型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#String"><span class="nav-number">2.1.</span> <span class="nav-text">String</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%84%E4%B8%AA%E6%8C%87%E4%BB%A4%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6"><span class="nav-number">2.1.1.</span> <span class="nav-text">各个指令的时间复杂度</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%95%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9CO-1"><span class="nav-number">2.1.1.1.</span> <span class="nav-text">单数据操作O(1)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9CO-N"><span class="nav-number">2.1.1.2.</span> <span class="nav-text">多数据操作O(N)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%A2%9E-%E5%87%8FO-1"><span class="nav-number">2.1.1.3.</span> <span class="nav-text">自增&#x2F;减O(1)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hash"><span class="nav-number">2.2.</span> <span class="nav-text">Hash</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%84%E4%B8%AA%E6%8C%87%E4%BB%A4%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6-1"><span class="nav-number">2.2.1.</span> <span class="nav-text">各个指令的时间复杂度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#List"><span class="nav-number">2.3.</span> <span class="nav-text">List</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%84%E4%B8%AA%E6%8C%87%E4%BB%A4%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6-2"><span class="nav-number">2.3.1.</span> <span class="nav-text">各个指令的时间复杂度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Set"><span class="nav-number">2.4.</span> <span class="nav-text">Set</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%84%E4%B8%AA%E6%8C%87%E4%BB%A4%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6-3"><span class="nav-number">2.4.1.</span> <span class="nav-text">各个指令的时间复杂度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ZSet"><span class="nav-number">2.5.</span> <span class="nav-text">ZSet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%84%E4%B8%AA%E6%8C%87%E4%BB%A4%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6-4"><span class="nav-number">2.5.1.</span> <span class="nav-text">各个指令的时间复杂度</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3%E3%80%81%E6%8C%81%E4%B9%85%E5%8C%96"><span class="nav-number">3.</span> <span class="nav-text">3、持久化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#RDB"><span class="nav-number">3.1.</span> <span class="nav-text">RDB</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A6%E5%8F%91%E6%9C%BA%E5%88%B6"><span class="nav-number">3.1.1.</span> <span class="nav-text">触发机制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E8%A7%A6%E5%8F%91"><span class="nav-number">3.1.1.1.</span> <span class="nav-text">手动触发</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E8%A7%A6%E5%8F%91"><span class="nav-number">3.1.1.2.</span> <span class="nav-text">自动触发</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bsave%E6%B5%81%E7%A8%8B"><span class="nav-number">3.1.2.</span> <span class="nav-text">bsave流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">3.1.3.</span> <span class="nav-text">优缺点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E7%82%B9"><span class="nav-number">3.1.3.1.</span> <span class="nav-text">优点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%BA%E7%82%B9"><span class="nav-number">3.1.3.2.</span> <span class="nav-text">缺点</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AOF"><span class="nav-number">3.2.</span> <span class="nav-text">AOF</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="nav-number">3.2.1.</span> <span class="nav-text">工作流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-4-0-%E5%AF%B9%E4%BA%8E%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6%E7%9A%84%E4%BC%98%E5%8C%96"><span class="nav-number">3.2.2.</span> <span class="nav-text">Redis 4.0 对于持久化机制的优化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AOF%E9%87%8D%E5%86%99%E6%9C%BA%E5%88%B6"><span class="nav-number">3.2.3.</span> <span class="nav-text">AOF重写机制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%87%8D%E5%86%99%E8%BF%87%E7%A8%8B%E7%9A%84%E8%A7%A6%E5%8F%91"><span class="nav-number">3.2.3.1.</span> <span class="nav-text">重写过程的触发</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%87%8D%E5%86%99%E6%B5%81%E7%A8%8B"><span class="nav-number">3.2.3.2.</span> <span class="nav-text">重写流程</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4%E3%80%81%E4%BA%8B%E5%8A%A1"><span class="nav-number">4.</span> <span class="nav-text">4、事务</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5%E3%80%81%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98"><span class="nav-number">5.</span> <span class="nav-text">5、缓存问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9"><span class="nav-number">5.1.</span> <span class="nav-text">缓存雪崩</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F"><span class="nav-number">5.2.</span> <span class="nav-text">缓存穿透</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95"><span class="nav-number">5.2.1.</span> <span class="nav-text">解决办法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C"><span class="nav-number">5.2.1.1.</span> <span class="nav-text">参数校验</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E6%97%A0%E6%95%88-key"><span class="nav-number">5.2.1.2.</span> <span class="nav-text">缓存无效 key</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8"><span class="nav-number">5.2.1.3.</span> <span class="nav-text">布隆过滤器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E7%A9%BA%E7%BB%93%E6%9E%9C"><span class="nav-number">5.2.1.4.</span> <span class="nav-text">缓存空结果</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6%E3%80%81%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6"><span class="nav-number">6.</span> <span class="nav-text">6、主从复制</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BB%BA%E7%AB%8B%E5%A4%8D%E5%88%B6"><span class="nav-number">6.1.</span> <span class="nav-text">建立复制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%8D%E5%88%B6%E8%BF%87%E7%A8%8B"><span class="nav-number">6.2.</span> <span class="nav-text">复制过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E4%B8%8B%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%96%B9%E6%B3%95"><span class="nav-number">6.3.</span> <span class="nav-text">主从复制下数据同步方法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7%E3%80%81%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F"><span class="nav-number">7.</span> <span class="nav-text">7、哨兵模式</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F"><span class="nav-number">7.1.</span> <span class="nav-text">部署方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="nav-number">7.2.</span> <span class="nav-text">实现原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E4%B8%AA%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1"><span class="nav-number">7.2.1.</span> <span class="nav-text">三个定时任务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E8%A7%82%E4%B8%8B%E7%BA%BF%E5%92%8C%E5%AE%A2%E8%A7%82%E4%B8%8B%E7%BA%BF"><span class="nav-number">7.2.2.</span> <span class="nav-text">主观下线和客观下线</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%86%E5%AF%BC%E8%80%85Sentinel%E8%8A%82%E7%82%B9%E7%9A%84%E9%80%89%E5%8F%96"><span class="nav-number">7.2.3.</span> <span class="nav-text">领导者Sentinel节点的选取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="nav-number">7.2.4.</span> <span class="nav-text">故障转移</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#8%E3%80%81%E9%9B%86%E7%BE%A4"><span class="nav-number">8.</span> <span class="nav-text">8、集群</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#9%E3%80%81Redis%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">9.</span> <span class="nav-text">9、Redis的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8redis-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E7%BC%93%E5%AD%98"><span class="nav-number">9.1.</span> <span class="nav-text">为什么要用redis&#x2F;为什么要用缓存</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8redis%E8%80%8C%E4%B8%8D%E7%9B%B4%E6%8E%A5%E5%9C%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E4%BD%BF%E7%94%A8map-guava%E5%81%9A%E7%BC%93%E5%AD%98%EF%BC%9F"><span class="nav-number">9.2.</span> <span class="nav-text">为什么使用redis而不直接在程序中使用map&#x2F;guava做缓存？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E5%92%8Cmemcached%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">9.3.</span> <span class="nav-text">redis和memcached的区别</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B1%E5%90%8C%E7%82%B9"><span class="nav-number">9.3.1.</span> <span class="nav-text">共同点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8C%BA%E5%88%AB"><span class="nav-number">9.3.2.</span> <span class="nav-text">区别</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis-%E4%B8%BA%E4%BB%80%E4%B9%88%E9%82%A3%E4%B9%88%E5%BF%AB%EF%BC%9F"><span class="nav-number">9.4.</span> <span class="nav-text">Redis 为什么那么快？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">9.5.</span> <span class="nav-text">Redis应用场景</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE"><span class="nav-number">9.5.1.</span> <span class="nav-text">热点数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%9A%E8%AF%9D%E7%BB%B4%E6%8C%81-Session"><span class="nav-number">9.5.2.</span> <span class="nav-text">会话维持 Session</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81-SETNX"><span class="nav-number">9.5.3.</span> <span class="nav-text">分布式锁 SETNX</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A1%A8%E7%BC%93%E5%AD%98"><span class="nav-number">9.5.4.</span> <span class="nav-text">表缓存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-list"><span class="nav-number">9.5.5.</span> <span class="nav-text">消息队列 list</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E6%95%B0%E5%99%A8-string"><span class="nav-number">9.5.6.</span> <span class="nav-text">计数器 string</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#10%E3%80%81Redis%E6%97%B6%E6%95%88%E6%80%A7"><span class="nav-number">10.</span> <span class="nav-text">10、Redis时效性</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis-%E7%BB%99%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E8%AE%BE%E7%BD%AE%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%E6%9C%89%E5%95%A5%E7%94%A8%EF%BC%9F"><span class="nav-number">10.1.</span> <span class="nav-text">Redis 给缓存数据设置过期时间有啥用？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis-%E5%88%A4%E6%96%AD%E6%95%B0%E6%8D%AE%E8%BF%87%E6%9C%9F%E7%9A%84%E5%8E%9F%E7%90%86"><span class="nav-number">10.2.</span> <span class="nav-text">Redis 判断数据过期的原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E8%BF%87%E6%9C%9F%E9%94%AE%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F"><span class="nav-number">10.3.</span> <span class="nav-text">redis过期键处理方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6%EF%BC%88MySQL%E4%B8%AD%E6%9C%892000w%E6%95%B0%E6%8D%AE%EF%BC%8CRedis%E4%B8%AD%E5%8F%AA%E5%AD%98%E4%BA%8620w%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81Redis%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%83%BD%E6%98%AF%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE%EF%BC%9F%EF%BC%89"><span class="nav-number">10.4.</span> <span class="nav-text">redis内存淘汰机制（MySQL中有2000w数据，Redis中只存了20w数据，如何保证Redis中的数据都是热点数据？）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#11%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="nav-number">11.</span> <span class="nav-text">11、分布式锁</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3Redis%E7%9A%84%E5%B9%B6%E5%8F%91%E7%AB%9E%E4%BA%89key%E9%97%AE%E9%A2%98"><span class="nav-number">11.1.</span> <span class="nav-text">如何解决Redis的并发竞争key问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redlock%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="nav-number">11.2.</span> <span class="nav-text">Redlock分布式锁</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%8E%E4%B9%88%E5%9C%A8%E5%8D%95%E7%82%B9%E4%B8%8A%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="nav-number">11.2.1.</span> <span class="nav-text">怎么在单点上实现分布式锁</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redlock%E7%AE%97%E6%B3%95"><span class="nav-number">11.2.2.</span> <span class="nav-text">Redlock算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%B1%E8%B4%A5%E9%87%8D%E8%AF%95"><span class="nav-number">11.2.3.</span> <span class="nav-text">失败重试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%BE%E9%94%81"><span class="nav-number">11.2.4.</span> <span class="nav-text">放锁</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E3%80%81%E5%B4%A9%E6%BA%83%E6%81%A2%E5%A4%8D%E5%92%8Cfsync"><span class="nav-number">11.2.5.</span> <span class="nav-text">性能、崩溃恢复和fsync</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RedLock%E7%BC%BA%E9%99%B7"><span class="nav-number">11.2.6.</span> <span class="nav-text">RedLock缺陷</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RedLock%E7%AE%97%E6%B3%95%E4%B8%8D%E5%8F%AF%E9%9D%A0%E7%9A%84%E5%9C%BA%E6%99%AF"><span class="nav-number">11.2.7.</span> <span class="nav-text">RedLock算法不可靠的场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E5%BC%8F"><span class="nav-number">11.2.8.</span> <span class="nav-text">解决方式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8Fencing%EF%BC%88%E6%A0%8F%E6%A0%85%EF%BC%89%E4%BD%BF%E9%94%81%E5%8F%98%E5%AE%89%E5%85%A8"><span class="nav-number">11.2.8.1.</span> <span class="nav-text">使用Fencing（栏栅）使锁变安全</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%97%B6%E9%97%B4%E6%9D%A5%E8%A7%A3%E5%86%B3%E4%B8%80%E8%87%B4%E6%80%A7"><span class="nav-number">11.2.8.2.</span> <span class="nav-text">使用时间来解决一致性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Redlock%E4%B8%8D%E5%8F%AF%E9%9D%A0%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="nav-number">11.2.8.3.</span> <span class="nav-text">Redlock不可靠的例子</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#12%E3%80%81%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E6%97%B6%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9F"><span class="nav-number">12.</span> <span class="nav-text">12、如何保证缓存与数据库双写时的数据一致性？</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%A0%E9%99%A4%E7%BC%93%E5%AD%98%E8%80%8C%E4%B8%8D%E6%98%AF%E6%9B%B4%E6%96%B0%E7%BC%93%E5%AD%98%EF%BC%9F"><span class="nav-number">12.1.</span> <span class="nav-text">为什么是删除缓存而不是更新缓存？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cache-Aside-Pattern%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">12.2.</span> <span class="nav-text">Cache Aside Pattern存在的问题</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#13%E3%80%81Redis%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0-%E7%94%A8%E5%88%B0%E4%BA%86%E5%93%AA%E4%BA%9B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="nav-number">13.</span> <span class="nav-text">13、Redis底层实现&#x2F;用到了哪些数据结构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AD%97%E5%85%B8%EF%BC%88%E4%B9%9F%E5%8F%AB%E5%93%88%E5%B8%8C%EF%BC%89"><span class="nav-number">13.1.</span> <span class="nav-text">字典（也叫哈希）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B7%B3%E8%B7%83%E8%A1%A8"><span class="nav-number">13.2.</span> <span class="nav-text">跳跃表</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#14%E3%80%81Sorted-Set%EF%BC%88%E5%8D%B3-ZSet-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%EF%BC%89"><span class="nav-number">14.</span> <span class="nav-text">14、Sorted Set（即 ZSet 实现原理）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ZipList"><span class="nav-number">14.1.</span> <span class="nav-text">ZipList</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Skiplist"><span class="nav-number">14.2.</span> <span class="nav-text">Skiplist</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B7%B3%E8%A1%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="nav-number">14.2.1.</span> <span class="nav-text">跳表数据结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Skiplist-%E4%B8%8E%E5%B9%B3%E8%A1%A1%E6%A0%91%E3%80%81%E5%93%88%E5%B8%8C%E8%A1%A8%E7%9A%84%E6%AF%94%E8%BE%83"><span class="nav-number">14.2.2.</span> <span class="nav-text">Skiplist 与平衡树、哈希表的比较</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-%E4%B8%AD-Skiplist-%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">14.2.3.</span> <span class="nav-text">Redis 中 Skiplist 的实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-Zset-%E9%87%87%E7%94%A8%E8%B7%B3%E8%A1%A8%E8%80%8C%E4%B8%8D%E6%98%AF%E5%B9%B3%E8%A1%A1%E6%A0%91%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="nav-number">14.2.4.</span> <span class="nav-text">Redis Zset 采用跳表而不是平衡树的原因</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">dmYang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">54</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">dmYang</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">566k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">8:34</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
    <br/>
	<a target="_blank" rel="noopener" href="http://www.miitbeian.gov.cn/">粤ICP备2020133211号-1</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/xxb/anime.min.js"></script>
  <script src="/xxb/velocity/velocity.min.js"></script>
  <script src="/xxb/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-backstretch/2.0.4/jquery.backstretch.min.js"></script>;
    <script>
      // 背景图片
      $("body").backstretch("https://csn.damyoung.cn/image-20201218100852830.png");
    </script>

    <!-- 页面点击小红心 -->
    <script type="text/javascript" src="/js/love.js"></script>
</body>
</html>
